{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1afc7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Inspired from toma - https://github.com/BlackHC/toma\n",
    "\"\"\"\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "def batch(func,*,batch_size = None,):\n",
    "    gc_cuda()\n",
    "\n",
    "    #\n",
    "#     if batch_size is None and 'batch_size' in kwargs:\n",
    "#         batch_size = kwargs['batch_size']\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            print(f\"Im in the decorator - {func.__name__}\")\n",
    "            return func(batch_size)\n",
    "        except RuntimeError as exception:\n",
    "            if batch_size > 1 and should_reduce_batch_size(exception):\n",
    "                batch_size //= 2\n",
    "                gc_cuda()\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "def gc_cuda():\n",
    "    \"\"\"Gargage collect Torch (CUDA) memory.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def should_reduce_batch_size(exception):\n",
    "    return is_cuda_out_of_memory(exception) or is_cudnn_snafu(exception) or is_out_of_cpu_memory(exception)\n",
    "\n",
    "def is_cuda_out_of_memory(exception):\n",
    "    return (\n",
    "        isinstance(exception, RuntimeError) and len(exception.args) == 1 and \"CUDA out of memory.\" in exception.args[0]\n",
    "    )\n",
    "\n",
    "def is_cudnn_snafu(exception):\n",
    "    # For/because of https://github.com/pytorch/pytorch/issues/4107\n",
    "    return (\n",
    "        isinstance(exception, RuntimeError)\n",
    "        and len(exception.args) == 1\n",
    "        and \"cuDNN error: CUDNN_STATUS_NOT_SUPPORTED.\" in exception.args[0]\n",
    "    )\n",
    "\n",
    "def is_out_of_cpu_memory(exception):\n",
    "    return (\n",
    "        isinstance(exception, RuntimeError)\n",
    "        and len(exception.args) == 1\n",
    "        and \"DefaultCPUAllocator: can't allocate memory\" in exception.args[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7082dcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "func - (2,), kwargs - {'b': 4}, batch_size - 4\n",
      "in function foo result - 6, batch_size - 4\n"
     ]
    }
   ],
   "source": [
    "def batch(func):\n",
    "    \"\"\"Run inference by deciding appropriate batch size on input\n",
    "    \"\"\"\n",
    "    def inner_wrapper(*args, batch_size, **kwargs):\n",
    "        while True:\n",
    "            try:\n",
    "                print(f\"func - {args}, kwargs - {kwargs}, batch_size - {batch_size}\")\n",
    "                res = func(*args,batch_size = batch_size, **kwargs)\n",
    "                return res\n",
    "            except RuntimeError as exception:\n",
    "                raise\n",
    "                if batch_size > 1 and should_reduce_batch_size(exception):\n",
    "                    batch_size //= 2\n",
    "                    gc_cuda()\n",
    "                else:\n",
    "                    raise\n",
    "    \n",
    "    return inner_wrapper\n",
    "\n",
    "@batch\n",
    "def foo(a,b, batch_size = 8):\n",
    "    \"\"\"\n",
    "    a, b - batch of data\n",
    "    \n",
    "    default batch size - 8 will try to reduce by half if it doesn't fit in memory\n",
    "    \"\"\"\n",
    "    print(f\"in function foo result - {a+b}, batch_size - {batch_size}\")\n",
    "    \n",
    "foo(2, b = 4, batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c1e29e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im in the decorator - foo\n",
      "I'm in function foo - None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@batch\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfoo\u001b[39m(batch_size, a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, b \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm in function foo - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mfoo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "@batch\n",
    "def foo(batch_size, a = 1, b = 2):\n",
    "    print(f\"I'm in function foo - {batch_size}\")\n",
    "    \n",
    "foo(batch_size = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a69352f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
