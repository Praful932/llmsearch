{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48fd4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocompletion\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "# Autoreload  \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944af2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import transformers\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, T5ForConditionalGeneration, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b390a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monkey Patching .generate function of `transformers` library\n"
     ]
    }
   ],
   "source": [
    "import llmsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25b6ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device - mps\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.backends.mps.is_built() and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "from llmsearch.utils.mem_utils import gc_cuda\n",
    "\n",
    "print(f\"Device - {device}\")\n",
    "\n",
    "def beep(duration = 1, frequency=440, rhythm=1):\n",
    "    sample_rate = 44100  # Standard audio sample rate\n",
    "    t = np.linspace(0, duration, int(duration * sample_rate), endpoint=False)\n",
    "    audio_data = np.sin(2*np.pi*frequency*t)  # Generate a sine wave\n",
    "    audio_data *= np.where(np.arange(len(audio_data)) % rhythm == 0, 1, 0)  # Apply rhythm\n",
    "    display(Audio(audio_data, rate=sample_rate, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c2fe830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset samsum (/Users/praful932/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b2ceab70864413a1120238f33f3cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca4a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 2\n",
    "samples_to_tune_on = datasets.Dataset.from_dict(dataset[\"train\"][:sample_size])\n",
    "samples_to_tune_on = samples_to_tune_on.rename_columns(column_mapping = {'dialogue' : 'X', 'summary' : \"y\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d40ddb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast = False)\n",
    "model =  AutoModelForSeq2SeqLM.from_pretrained(model_id).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46ba55bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation: Amanda: I baked  cookies. Do you want some?\r\n",
      "Jerry: Sure!\r\n",
      "Amanda: I'll bring you tomorrow :-)\n",
      "Summary:\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "X = samples_to_tune_on[0]['X']\n",
    "\n",
    "pt = langchain.PromptTemplate.from_template(\"Conversation: {X}\\nSummary:\")\n",
    "\n",
    "print(pt.format_prompt(X = X).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cddba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "    \n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def get_rouge_score(y_true: List, y_pred: List):\n",
    "    preds, gts = postprocess_text(preds=y_pred, labels=y_true)\n",
    "\n",
    "    result = rouge_metric.compute(predictions=preds, references=gts, use_stemmer=True)\n",
    "    return result['rouge2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deca2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmsearch.tuner import Tuner\n",
    "from llmsearch.utils.mem_utils import get_total_available_ram, get_gpu_information\n",
    "from llmsearch.utils.logging_utils import set_verbosity_info, set_verbosity_debug\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "seed = 42\n",
    "\n",
    "set_verbosity_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87baa229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner_ob = Tuner(model = model,tokenizer = tokenizer,dataset = samples_to_tune_on,\n",
    "                 device = device, batch_size = 512,\n",
    "                 tokenizer_encoding_kwargs={'padding': True, 'truncation': True, 'max_length': 512},\n",
    "                 tokenizer_decoding_kwargs = {'skip_special_tokens' : True,  'spaces_between_special_tokens' : False}, \n",
    "                 scorer = get_rouge_score, prompt_template = pt, is_encoder_decoder = True, seed = seed, column_mapping = {\"text_column_name\": \"X\", \"label_column_name\": \"y\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "740358a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 00:52:26.803 - llmsearch.utils.mem_utils:145 - INFO - Starting inference with generation parameters - {'max_new_tokens': 120, 'do_sample': True, 'generation_seed': 42, 'mirostat_mode': 2, 'mirostat_tau': 5}\n",
      "2023-09-14 00:52:26.803 - llmsearch.utils.mem_utils:149 - INFO - Performing inference with batch_size - 512\n",
      "2023-09-14 00:52:26.804 - llmsearch.utils.model_utils:102 - INFO - Detected generation type - Sampling\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8bfeed418541e0a1a2931224a51bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here - 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praful932/Library/Caches/pypoetry/virtualenvs/bhaasha-VBcDHvMD-py3.8/lib/python3.8/site-packages/transformers/generation/utils.py:719: UserWarning: MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\n",
      "  input_ids = input_ids.repeat_interleave(expand_size, dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - 1\n",
      "sorted logits 1st example - tensor([ 6.6590,  2.2148, -0.0925, -1.6710], device='mps:0')\n",
      "sorted indices - [21542, 16637, 24571, 24244, 13390]\n",
      "Probability 1st example - tensor([9.8389e-01, 1.1558e-02, 1.1503e-03, 2.3729e-04], device='mps:0')\n",
      "tensor(0.9839, device='mps:0')\n",
      "Row logit tensor sum - 8.781220436096191\n",
      "Row sum - 8.781220436096191\n",
      "softmaxed vals - tensor([0.9872, 0.0116, 0.0012], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.9872], device='mps:0')\n",
      "obs surprise value - 0.018514678748829252\n",
      "indices to remove - 516098713\n",
      "sum value - 6.658950328826904\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praful932/Library/Caches/pypoetry/virtualenvs/bhaasha-VBcDHvMD-py3.8/lib/python3.8/site-packages/transformers/generation/utils.py:2671: UserWarning: MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:1271.)\n",
      "  if unfinished_sequences.max() == 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - 2\n",
      "sorted logits 1st example - tensor([3.2360, 1.6313, 0.4579, 0.0527], device='mps:0')\n",
      "sorted indices - [13635, 56, 11, 65, 19]\n",
      "Probability 1st example - tensor([0.6718, 0.1350, 0.0418, 0.0278], device='mps:0')\n",
      "tensor(0.6718, device='mps:0')\n",
      "Row logit tensor sum - -47.7884521484375\n",
      "Row sum - -47.7884521484375\n",
      "softmaxed vals - tensor([0.6907, 0.1388, 0.0429, 0.0286], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0075], device='mps:0')\n",
      "obs surprise value - 7.067882950159778\n",
      "indices to remove - 516117509\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 3\n",
      "sorted logits 1st example - tensor([ 2.1572,  0.8451,  0.0723, -1.0812], device='mps:0')\n",
      "sorted indices - [12, 128, 5081, 7364, 3]\n",
      "Probability 1st example - tensor([0.5925, 0.1595, 0.0737, 0.0232], device='mps:0')\n",
      "tensor(0.5925, device='mps:0')\n",
      "Row logit tensor sum - -96.61461639404297\n",
      "Row sum - -96.61461639404297\n",
      "softmaxed vals - tensor([0.6300, 0.1696, 0.0783, 0.0247], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0072], device='mps:0')\n",
      "obs surprise value - 7.119590465454985\n",
      "indices to remove - 516103618\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 4\n",
      "sorted logits 1st example - tensor([ 1.2505, -1.0032, -2.4510, -3.5484], device='mps:0')\n",
      "sorted indices - [12, 31, 11, 21, 3]\n",
      "Probability 1st example - tensor([0.8497, 0.0892, 0.0210, 0.0070], device='mps:0')\n",
      "tensor(0.8497, device='mps:0')\n",
      "Row logit tensor sum - -26.994464874267578\n",
      "Row sum - -26.994464874267578\n",
      "softmaxed vals - tensor([0.8614, 0.0905, 0.0213, 0.0071], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0032], device='mps:0')\n",
      "obs surprise value - 8.28642291260206\n",
      "indices to remove - 516115174\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 5\n",
      "sorted logits 1st example - tensor([ 1.5418, -0.4005, -0.6595, -0.9503], device='mps:0')\n",
      "sorted indices - [5, 11, 21, 12, 6]\n",
      "Probability 1st example - tensor([0.6265, 0.0898, 0.0693, 0.0518], device='mps:0')\n",
      "tensor(0.6265, device='mps:0')\n",
      "Row logit tensor sum - -72.5335922241211\n",
      "Row sum - -72.5335922241211\n",
      "softmaxed vals - tensor([0.6397, 0.0917, 0.0708, 0.0529], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0136], device='mps:0')\n",
      "obs surprise value - 6.196222523045104\n",
      "indices to remove - 516120177\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 6\n",
      "sorted logits 1st example - tensor([ 1.7184,  1.4498, -0.2170, -0.3557], device='mps:0')\n",
      "sorted indices - [255, 3, 24, 16637, 79]\n",
      "Probability 1st example - tensor([0.4491, 0.3433, 0.0648, 0.0564], device='mps:0')\n",
      "tensor(0.4491, device='mps:0')\n",
      "Row logit tensor sum - -23.9764404296875\n",
      "Row sum - -23.9764404296875\n",
      "softmaxed vals - tensor([0.4632, 0.3541, 0.0669, 0.0582], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0062], device='mps:0')\n",
      "obs surprise value - 7.342487351522139\n",
      "indices to remove - 516098713\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 7\n",
      "sorted logits 1st example - tensor([ 0.7425, -0.3553, -1.9162, -2.4444], device='mps:0')\n",
      "sorted indices - [56, 54, 11, 31, 19]\n",
      "Probability 1st example - tensor([0.5779, 0.1928, 0.0405, 0.0239], device='mps:0')\n",
      "tensor(0.5779, device='mps:0')\n",
      "Row logit tensor sum - -65.13998413085938\n",
      "Row sum - -65.13998413085938\n",
      "softmaxed vals - tensor([0.6065, 0.2023, 0.0425, 0.0250], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0123], device='mps:0')\n",
      "obs surprise value - 6.347632244328421\n",
      "indices to remove - 516120252\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 8\n",
      "sorted logits 1st example - tensor([-0.9962, -2.7023, -2.8556, -2.8574], device='mps:0')\n",
      "sorted indices - [1544, 26, 88, 31, 9000]\n",
      "Probability 1st example - tensor([0.3467, 0.0630, 0.0540, 0.0539], device='mps:0')\n",
      "tensor(0.3467, device='mps:0')\n",
      "Row logit tensor sum - -254.713134765625\n",
      "Row sum - -254.713134765625\n",
      "softmaxed vals - tensor([0.3781, 0.0686, 0.0589, 0.0588], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0240], device='mps:0')\n",
      "obs surprise value - 5.382267665015073\n",
      "indices to remove - 516120204\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 9\n",
      "sorted logits 1st example - tensor([-1.6935, -3.1431, -3.6960, -3.7694], device='mps:0')\n",
      "sorted indices - [7, 31, 3198, 53, 75]\n",
      "Probability 1st example - tensor([0.3357, 0.0788, 0.0453, 0.0421], device='mps:0')\n",
      "tensor(0.3357, device='mps:0')\n",
      "Row logit tensor sum - -335.9856262207031\n",
      "Row sum - -335.9856262207031\n",
      "softmaxed vals - tensor([0.3972, 0.0932, 0.0536, 0.0498], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0190], device='mps:0')\n",
      "obs surprise value - 5.721430304053523\n",
      "indices to remove - 516120226\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 10\n",
      "sorted logits 1st example - tensor([-0.7589, -1.5261, -1.7195, -1.8757], device='mps:0')\n",
      "sorted indices - [32, 23, 76, 56, 29]\n",
      "Probability 1st example - tensor([0.1612, 0.0748, 0.0617, 0.0528], device='mps:0')\n",
      "tensor(0.1612, device='mps:0')\n",
      "Row logit tensor sum - -240.2235107421875\n",
      "Row sum - -240.2235107421875\n",
      "softmaxed vals - tensor([0.2064, 0.0958, 0.0790, 0.0676], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0290], device='mps:0')\n",
      "obs surprise value - 5.109685340372173\n",
      "indices to remove - 516120246\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 11\n",
      "sorted logits 1st example - tensor([ 1.3682,  1.0074,  0.1873, -0.3513], device='mps:0')\n",
      "sorted indices - [56, 7, 54, 19, 3]\n",
      "Probability 1st example - tensor([0.1691, 0.1179, 0.0519, 0.0303], device='mps:0')\n",
      "tensor(0.1691, device='mps:0')\n",
      "Row logit tensor sum - -120.39584350585938\n",
      "Row sum - -120.39584350585938\n",
      "softmaxed vals - tensor([0.2373, 0.1655, 0.0729, 0.0425], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0280], device='mps:0')\n",
      "obs surprise value - 5.157947424877538\n",
      "indices to remove - 516120229\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 12\n",
      "sorted logits 1st example - tensor([2.2838, 0.7774, 0.6242, 0.0771], device='mps:0')\n",
      "sorted indices - [7, 376, 160, 135, 16637]\n",
      "Probability 1st example - tensor([0.4201, 0.0931, 0.0799, 0.0462], device='mps:0')\n",
      "tensor(0.4201, device='mps:0')\n",
      "Row logit tensor sum - -44.74970245361328\n",
      "Row sum - -44.74970245361328\n",
      "softmaxed vals - tensor([0.5052, 0.1120, 0.0961, 0.0556], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0160], device='mps:0')\n",
      "obs surprise value - 5.965601160290269\n",
      "indices to remove - 516120250\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 13\n",
      "sorted logits 1st example - tensor([ 1.5573,  1.0432, -0.3448, -0.8681], device='mps:0')\n",
      "sorted indices - [16637, 1, 21542, 451, 216]\n",
      "Probability 1st example - tensor([0.4992, 0.2985, 0.0745, 0.0442], device='mps:0')\n",
      "tensor(0.4992, device='mps:0')\n",
      "Row logit tensor sum - -9.965428352355957\n",
      "Row sum - -9.965428352355957\n",
      "softmaxed vals - tensor([0.5206, 0.3114, 0.0777, 0.0460], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0021], device='mps:0')\n",
      "obs surprise value - 8.87756060566448\n",
      "indices to remove - 516120161\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 14\n",
      "sorted logits 1st example - tensor([2.4792, 1.6742, 1.2100, 0.1592], device='mps:0')\n",
      "sorted indices - [31, 56, 19, 133, 1416]\n",
      "Probability 1st example - tensor([0.4488, 0.2007, 0.1262, 0.0441], device='mps:0')\n",
      "tensor(0.4488, device='mps:0')\n",
      "Row logit tensor sum - -31.525890350341797\n",
      "Row sum - -31.525890350341797\n",
      "softmaxed vals - tensor([0.4678, 0.2092, 0.1315, 0.0460], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0089], device='mps:0')\n",
      "obs surprise value - 6.814893341832159\n",
      "indices to remove - 516120030\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 15\n",
      "sorted logits 1st example - tensor([ 3.9373,  1.0787, -0.0874, -1.3492], device='mps:0')\n",
      "sorted indices - [36, 369, 43, 3658, 583]\n",
      "Probability 1st example - tensor([0.8746, 0.0502, 0.0156, 0.0044], device='mps:0')\n",
      "tensor(0.8746, device='mps:0')\n",
      "Row logit tensor sum - -4.548815727233887\n",
      "Row sum - -4.548815727233887\n",
      "softmaxed vals - tensor([0.9094, 0.0522, 0.0163, 0.0046], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0033], device='mps:0')\n",
      "obs surprise value - 8.263581448761174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices to remove - 516119974\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 16\n",
      "sorted logits 1st example - tensor([1.5522, 1.0980, 0.8778, 0.6058], device='mps:0')\n",
      "sorted indices - [12, 28, 168, 2177, 5721]\n",
      "Probability 1st example - tensor([0.2490, 0.1581, 0.1268, 0.0966], device='mps:0')\n",
      "tensor(0.2490, device='mps:0')\n",
      "Row logit tensor sum - -28.028358459472656\n",
      "Row sum - -28.028358459472656\n",
      "softmaxed vals - tensor([0.2835, 0.1800, 0.1444, 0.1100], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0275], device='mps:0')\n",
      "obs surprise value - 5.185305672740188\n",
      "indices to remove - 516120239\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 17\n",
      "sorted logits 1st example - tensor([2.0087, 1.1472, 0.6497, 0.3960], device='mps:0')\n",
      "sorted indices - [8, 5721, 3, 12, 160]\n",
      "Probability 1st example - tensor([0.2922, 0.1235, 0.0751, 0.0583], device='mps:0')\n",
      "tensor(0.2922, device='mps:0')\n",
      "Row logit tensor sum - -33.124168395996094\n",
      "Row sum - -33.124168395996094\n",
      "softmaxed vals - tensor([0.3645, 0.1540, 0.0936, 0.0727], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0183], device='mps:0')\n",
      "obs surprise value - 5.771919693827305\n",
      "indices to remove - 516120175\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 18\n",
      "sorted logits 1st example - tensor([2.0419, 1.2323, 0.6727, 0.4168], device='mps:0')\n",
      "sorted indices - [239, 13, 9133, 1781, 1962]\n",
      "Probability 1st example - tensor([0.3433, 0.1528, 0.0873, 0.0676], device='mps:0')\n",
      "tensor(0.3433, device='mps:0')\n",
      "Row logit tensor sum - -29.004669189453125\n",
      "Row sum - -29.004669189453125\n",
      "softmaxed vals - tensor([0.3980, 0.1771, 0.1012, 0.0784], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0156], device='mps:0')\n",
      "obs surprise value - 6.0022697196990356\n",
      "indices to remove - 516116432\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 19\n",
      "sorted logits 1st example - tensor([ 1.5270, -0.4002, -0.6700, -0.9276], device='mps:0')\n",
      "sorted indices - [5, 11, 5721, 6, 28]\n",
      "Probability 1st example - tensor([0.6356, 0.0925, 0.0706, 0.0546], device='mps:0')\n",
      "tensor(0.6356, device='mps:0')\n",
      "Row logit tensor sum - -32.9827766418457\n",
      "Row sum - -32.9827766418457\n",
      "softmaxed vals - tensor([0.6765, 0.0985, 0.0752, 0.0581], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0071], device='mps:0')\n",
      "obs surprise value - 7.145264941770928\n",
      "indices to remove - 516120213\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 20\n",
      "sorted logits 1st example - tensor([3.0945, 1.9809, 1.9504, 1.8943], device='mps:0')\n",
      "sorted indices - [192, 16, 3, 44, 416]\n",
      "Probability 1st example - tensor([0.2134, 0.0701, 0.0680, 0.0643], device='mps:0')\n",
      "tensor(0.2134, device='mps:0')\n",
      "Row logit tensor sum - 10.404422760009766\n",
      "Row sum - 10.404422760009766\n",
      "softmaxed vals - tensor([0.2790, 0.0916, 0.0889, 0.0840], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0417], device='mps:0')\n",
      "obs surprise value - 4.5834702054043035\n",
      "indices to remove - 516120175\n",
      "sum value - 1.1940386295318604\n",
      "\n",
      "\n",
      "Iteration - 21\n",
      "sorted logits 1st example - tensor([5.9597, 3.3776, 3.3649, 3.1601], device='mps:0')\n",
      "sorted indices - [3823, 44, 28, 30, 16]\n",
      "Probability 1st example - tensor([0.6160, 0.0466, 0.0460, 0.0375], device='mps:0')\n",
      "tensor(0.6160, device='mps:0')\n",
      "Row logit tensor sum - 26.712810516357422\n",
      "Row sum - 26.712810516357422\n",
      "softmaxed vals - tensor([0.7592, 0.0574, 0.0567, 0.0462], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0111], device='mps:0')\n",
      "obs surprise value - 6.4987222253540216\n",
      "indices to remove - 516120242\n",
      "sum value - 1.73069429397583\n",
      "\n",
      "\n",
      "Iteration - 22\n",
      "sorted logits 1st example - tensor([ 1.5793,  1.1816, -0.2430, -0.7791], device='mps:0')\n",
      "sorted indices - [8, 160, 135, 192, 70]\n",
      "Probability 1st example - tensor([0.4400, 0.2956, 0.0711, 0.0416], device='mps:0')\n",
      "tensor(0.4400, device='mps:0')\n",
      "Row logit tensor sum - -17.0628719329834\n",
      "Row sum - -17.0628719329834\n",
      "softmaxed vals - tensor([0.4599, 0.3090, 0.0744, 0.0435], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0116], device='mps:0')\n",
      "obs surprise value - 6.430350988400401\n",
      "indices to remove - 516120080\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 23\n",
      "sorted logits 1st example - tensor([3.4407, 1.9874, 1.8367, 0.9643], device='mps:0')\n",
      "sorted indices - [5, 3823, 477, 5056, 6]\n",
      "Probability 1st example - tensor([0.3757, 0.0878, 0.0755, 0.0316], device='mps:0')\n",
      "tensor(0.3757, device='mps:0')\n",
      "Row logit tensor sum - 3.440023899078369\n",
      "Row sum - 3.440023899078369\n",
      "softmaxed vals - tensor([0.5053, 0.1181, 0.1016, 0.0425], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0213], device='mps:0')\n",
      "obs surprise value - 5.553255283242131\n",
      "indices to remove - 516118153\n",
      "sum value - 0.27407848834991455\n",
      "\n",
      "\n",
      "Iteration - 24\n",
      "sorted logits 1st example - tensor([ 1.9264, -0.4937, -0.7555, -1.7700], device='mps:0')\n",
      "sorted indices - [5, 5721, 6, 11, 56]\n",
      "Probability 1st example - tensor([0.6840, 0.0608, 0.0468, 0.0170], device='mps:0')\n",
      "tensor(0.6840, device='mps:0')\n",
      "Row logit tensor sum - -17.703025817871094\n",
      "Row sum - -17.703025817871094\n",
      "softmaxed vals - tensor([0.7813, 0.0695, 0.0535, 0.0194], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0112], device='mps:0')\n",
      "obs surprise value - 6.483934274146141\n",
      "indices to remove - 516120243\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 25\n",
      "sorted logits 1st example - tensor([2.7292, 2.5560, 2.4030, 2.0481], device='mps:0')\n",
      "sorted indices - [160, 8, 129, 16637, 3]\n",
      "Probability 1st example - tensor([0.0999, 0.0840, 0.0721, 0.0505], device='mps:0')\n",
      "tensor(0.0999, device='mps:0')\n",
      "Row logit tensor sum - 27.231739044189453\n",
      "Row sum - 27.231739044189453\n",
      "softmaxed vals - tensor([0.1483, 0.1247, 0.1070, 0.0751], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0325], device='mps:0')\n",
      "obs surprise value - 4.942767601352971\n",
      "indices to remove - 516120038\n",
      "sum value - 1.2114421129226685\n",
      "\n",
      "\n",
      "Iteration - 26\n",
      "sorted logits 1st example - tensor([1.7976, 0.2153, 0.1346, 0.1216], device='mps:0')\n",
      "sorted indices - [3, 125, 16637, 5, 160]\n",
      "Probability 1st example - tensor([0.4020, 0.0826, 0.0762, 0.0752], device='mps:0')\n",
      "tensor(0.4020, device='mps:0')\n",
      "Row logit tensor sum - -9.862497329711914\n",
      "Row sum - -9.862497329711914\n",
      "softmaxed vals - tensor([0.4598, 0.0945, 0.0872, 0.0860], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0261], device='mps:0')\n",
      "obs surprise value - 5.26135312038355\n",
      "indices to remove - 516120120\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 27\n",
      "sorted logits 1st example - tensor([ 2.4850,  1.5981, -0.8299, -0.8348], device='mps:0')\n",
      "sorted indices - [5, 5721, 44, 16, 30]\n",
      "Probability 1st example - tensor([0.5404, 0.2226, 0.0196, 0.0195], device='mps:0')\n",
      "tensor(0.5404, device='mps:0')\n",
      "Row logit tensor sum - -5.935232162475586\n",
      "Row sum - -5.935232162475586\n",
      "softmaxed vals - tensor([0.6203, 0.2555, 0.0225, 0.0224], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([7], device='mps:0')\n",
      "logit val - tensor([0.0135], device='mps:0')\n",
      "obs surprise value - 6.212975768848041\n",
      "indices to remove - 516119714\n",
      "sum value - 0.0\n",
      "\n",
      "\n",
      "Iteration - 28\n",
      "sorted logits 1st example - tensor([ 2.3018,  2.2766, -1.2917, -1.8951], device='mps:0')\n",
      "sorted indices - [5, 5721, 6, 11, 469]\n",
      "Probability 1st example - tensor([0.4592, 0.4478, 0.0126, 0.0069], device='mps:0')\n",
      "tensor(0.4592, device='mps:0')\n",
      "Row logit tensor sum - 3.2867088317871094\n",
      "Row sum - 3.2867088317871094\n",
      "softmaxed vals - tensor([0.4994, 0.4869, 0.0137], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([1], device='mps:0')\n",
      "logit val - tensor([0.4869], device='mps:0')\n",
      "obs surprise value - 1.0382751264858443\n",
      "indices to remove - 516114534\n",
      "sum value - 2.2765917778015137\n",
      "\n",
      "\n",
      "Iteration - 29\n",
      "sorted logits 1st example - tensor([ 1.9059, -2.6453, -3.2718, -3.6507], device='mps:0')\n",
      "sorted indices - [5, 6, 1379, 44, 11]\n",
      "Probability 1st example - tensor([0.9562, 0.0101, 0.0054, 0.0037], device='mps:0')\n",
      "tensor(0.9562, device='mps:0')\n",
      "Row logit tensor sum - -0.7394630908966064\n",
      "Row sum - -0.7394630908966064\n",
      "softmaxed vals - tensor([0.9896, 0.0104], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.9896], device='mps:0')\n",
      "obs surprise value - 0.01514689429902088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices to remove - 516120250\n",
      "sum value - 1.9058787822723389\n",
      "\n",
      "\n",
      "Iteration - 30\n",
      "sorted logits 1st example - tensor([ 1.9662, -1.2483, -1.6524, -2.7703], device='mps:0')\n",
      "sorted indices - [1, 16637, 21542, 451, 328]\n",
      "Probability 1st example - tensor([0.9099, 0.0366, 0.0244, 0.0080], device='mps:0')\n",
      "tensor(0.9099, device='mps:0')\n",
      "Row logit tensor sum - -3.7048492431640625\n",
      "Row sum - -3.7048492431640625\n",
      "softmaxed vals - tensor([0.9296, 0.0373, 0.0249, 0.0082], device='mps:0')\n",
      "Seeding with 42\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.9296], device='mps:0')\n",
      "obs surprise value - 0.10536677576175119\n",
      "indices to remove - 516120254\n",
      "sum value - 1.9661556482315063\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 00:53:45.985 - llmsearch.utils.mem_utils:179 - INFO - Finished running inference, took 79.181386 secs\n"
     ]
    }
   ],
   "source": [
    "# Earlier\n",
    "from llmsearch.utils.model_utils import seed_everything\n",
    "\n",
    "\"\"\"\n",
    "parameters and how they affect do_sample == False\n",
    "1. temperature - output does not change - greedy decoding\n",
    "2. top_k - output does not change - greedy decoding\n",
    "3. repetition_penalty - output changes\n",
    "4. no_repeat_ngram_size - output changes\n",
    "\"\"\"\n",
    "\n",
    "# seed_everything(seed)\n",
    "\n",
    "initial_generation_params1 = {\n",
    "    'max_new_tokens' : 120,\n",
    "#     'repetition_penalty'  : 0.6,\n",
    "#     'repetition_penalty_range'  : 5,\n",
    "#     'temperature' : 0.7,\n",
    "    'do_sample' : True,\n",
    "    'generation_seed' : 42,\n",
    "    'mirostat_mode': 2,\n",
    "    'mirostat_tau' : 5,\n",
    "#     'top_a' : 0.1,\n",
    "}\n",
    "score, outputs1 = tuner_ob.get_score(initial_generation_params1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb962ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e38cf433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amanda wants Jerry cookies so Amanda mnad. It should go in one sitting or one of these ones to see them again tomorrow.', 'Amanda wants Jerry cookies so Amanda mnad. It should go in one sitting or one of these ones to see them again tomorrow.']\n"
     ]
    }
   ],
   "source": [
    "print(outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c497ded9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amanda baked cookies with Jerry. She has another brother. Amanda will bring her tomorrow.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14664d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amanda baked cookies with him. Jerry will bring Amanda',\n",
       " 'Olivia is voting for the Liberals so she will',\n",
       " 'Kim is going to do some things now and won',\n",
       " \"Edward's not in ovl me\",\n",
       " 'Sam and Naomi have made a point of asking',\n",
       " 'Neville was married on September 17th as she',\n",
       " 'Cassandra has completed the homework tomorrow',\n",
       " 'Sarah sent James lyrics to the song she loved.',\n",
       " 'Noah is meeting Madison with her boss at the Man',\n",
       " 'Matt and Agnes both know each other in']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ac45f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kim will drop some off of her - for later. Tim will use Pomodoro technique for doing something for themselves and she suggests poetry.',\n",
       " 'Kim will drop some off of her - for later. Tim will use Pomodoro technique for doing something for themselves and she suggests poetry.',\n",
       " 'Kim will drop some off of her - for later. Tim will use Pomodoro technique for doing something for themselves and she suggests poetry.',\n",
       " 'Kim will drop some off of her - for later. Tim will use Pomodoro technique for doing something for themselves and she suggests poetry.',\n",
       " 'Kim will drop some off of her - for later. Tim will use Pomodoro technique for doing something for themselves and she suggests poetry.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0653ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y_t, y_p in zip(tuner_ob.dataset['y'], outputs1):\n",
    "    print(y_p)\n",
    "    print(y_t,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745852b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22995afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_param_grid = {\n",
    "    \"max_new_tokens\": [120],\n",
    "    \"temperature\": list(np.linspace(start=0.1, stop=1.0,num=10)),\n",
    "    'top_k' : list(map(int,np.linspace(start=10, stop=50,num=5))),\n",
    "    \"top_p\": [0.75, 0.8, 0.9, 1.0],\n",
    "    'do_sample' : [True, False],\n",
    "    'generation_seed' : [42],\n",
    "    'repetition_penalty' : [1.0, 1.2],\n",
    "    'no_repeat_ngram_size' : [0,2,3],\n",
    "}\n",
    "\n",
    "hyp_param_grid_2= {\n",
    "    \"max_new_tokens\": [120],\n",
    "    \"temperature\": list(np.linspace(start=0.1, stop=1.0,num=10000)),\n",
    "    'top_k' : list(map(int,np.linspace(start=10, stop=50,num=5000))),\n",
    "    \"top_p\": list(map(int,np.linspace(start=10, stop=50,num=5000))),\n",
    "    'do_sample' : [True],\n",
    "    'generation_seed' : [42],\n",
    "    'num_beams' : [1],\n",
    "#     'repetition_penalty' : [1.0, 1.2],\n",
    "#     'no_repeat_ngram_size' : [0,2,3],\n",
    "}\n",
    "\n",
    "scorer = make_scorer(score_func=get_rouge_score, greater_is_better=True)\n",
    "\n",
    "\n",
    "clf = RandomizedSearchCV(\n",
    "    estimator=tuner_ob.estimator,\n",
    "    param_distributions=hyp_param_grid_2,\n",
    "    n_iter = 2,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state = 42,\n",
    "    n_jobs=None,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "5 fold means, whole sample set of 100 examples will be split into 80:20 ratio\n",
    "for each hyper_parameter set we have a model f(hyper_params)\n",
    "    - we will evaluate this model and get the cross val score (test on each 20 samples 5 times, while training on the rest 80 each time)\n",
    "    - we get the score on the quality of hyperparams by evaluating the model with the hyperparams on the unseen 1 fold\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f070d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 = 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967d672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X=tuner_ob.dataset[\"X\"], y=tuner_ob.dataset[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a41bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e8919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e1269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.best_estimator_.set_params(**clf.best_params_).get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c02681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "clone(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee361ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a846cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d9506",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f27049",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
