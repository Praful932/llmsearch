{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48fd4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocompletion\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "# Autoreload  \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944af2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoreload\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import transformers\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, T5ForConditionalGeneration, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b390a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monkey Patching .generate function of `transformers` library\n"
     ]
    }
   ],
   "source": [
    "import llmsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b25b6ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device - mps\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "\n",
    "if torch.backends.mps.is_built() and torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "from llmsearch.utils.mem_utils import gc_cuda\n",
    "\n",
    "print(f\"Device - {device}\")\n",
    "\n",
    "def beep(duration = 1, frequency=440, rhythm=1):\n",
    "    sample_rate = 44100  # Standard audio sample rate\n",
    "    t = np.linspace(0, duration, int(duration * sample_rate), endpoint=False)\n",
    "    audio_data = np.sin(2*np.pi*frequency*t)  # Generate a sine wave\n",
    "    audio_data *= np.where(np.arange(len(audio_data)) % rhythm == 0, 1, 0)  # Apply rhythm\n",
    "    display(Audio(audio_data, rate=sample_rate, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c2fe830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset samsum (/Users/praful932/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2622412aac5a47a8ae56a414e06542bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca4a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1\n",
    "samples_to_tune_on = datasets.Dataset.from_dict(dataset[\"train\"][:sample_size])\n",
    "samples_to_tune_on = samples_to_tune_on.rename_columns(column_mapping = {'dialogue' : 'X', 'summary' : \"y\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d40ddb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast = False)\n",
    "model =  AutoModelForSeq2SeqLM.from_pretrained(model_id).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46ba55bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation: Amanda: I baked  cookies. Do you want some?\r\n",
      "Jerry: Sure!\r\n",
      "Amanda: I'll bring you tomorrow :-)\n",
      "Summary:\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "X = samples_to_tune_on[0]['X']\n",
    "\n",
    "pt = langchain.PromptTemplate.from_template(\"Conversation: {X}\\nSummary:\")\n",
    "\n",
    "print(pt.format_prompt(X = X).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cddba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "    \n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def get_rouge_score(y_true: List, y_pred: List):\n",
    "    preds, gts = postprocess_text(preds=y_pred, labels=y_true)\n",
    "\n",
    "    result = rouge_metric.compute(predictions=preds, references=gts, use_stemmer=True)\n",
    "    return result['rouge2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deca2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmsearch.tuner import Tuner\n",
    "from llmsearch.utils.mem_utils import get_total_available_ram, get_gpu_information\n",
    "from llmsearch.utils.logging_utils import set_verbosity_info, set_verbosity_debug\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "seed = 42\n",
    "\n",
    "set_verbosity_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87baa229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuner_ob = Tuner(model = model,tokenizer = tokenizer,dataset = samples_to_tune_on,\n",
    "                 device = device, batch_size = 512,\n",
    "                 tokenizer_encoding_kwargs={'padding': True, 'truncation': True, 'max_length': 512},\n",
    "                 tokenizer_decoding_kwargs = {'skip_special_tokens' : True,  'spaces_between_special_tokens' : False}, \n",
    "                 scorer = get_rouge_score, prompt_template = pt, is_encoder_decoder = True, seed = seed, column_mapping = {\"text_column_name\": \"X\", \"label_column_name\": \"y\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a641629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples_to_tune_on['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a227ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740358a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-03 18:23:24.206 - llmsearch.utils.mem_utils:145 - INFO - Starting inference with generation parameters - {'max_new_tokens': 120, 'do_sample': True, 'generation_seed': 42, 'mirostat_mode': 2, 'mirostat_tau': 5}\n",
      "2023-09-03 18:23:24.207 - llmsearch.utils.mem_utils:149 - INFO - Performing inference with batch_size - 512\n",
      "2023-09-03 18:23:24.208 - llmsearch.utils.model_utils:101 - INFO - Detected generation type - Sampling\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375125342c2c4a11aaec8285d957626c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here - 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praful932/Library/Caches/pypoetry/virtualenvs/bhaasha-VBcDHvMD-py3.8/lib/python3.8/site-packages/transformers/generation/utils.py:719: UserWarning: MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\n",
      "  input_ids = input_ids.repeat_interleave(expand_size, dim=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - 1\n",
      "[21542, 16637, 24571, 24244, 13390]\n",
      "sorted logits tensor sum - -580818.8125\n",
      "[0.9838887453079224, 0.011557682417333126, 0.0011503249406814575, 0.00023728713858872652]\n",
      "row logit tensor sum - 8.781220436096191\n",
      "Break index i - 3\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.9872], device='mps:0')\n",
      "obs surprise value - 0.018514678748829252\n",
      "indices to remove - 516098713\n",
      "sum value - 6.658950328826904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/praful932/Library/Caches/pypoetry/virtualenvs/bhaasha-VBcDHvMD-py3.8/lib/python3.8/site-packages/transformers/generation/utils.py:2671: UserWarning: MPS: no support for int64 min/max ops, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/ReduceOps.mm:1271.)\n",
      "  if unfinished_sequences.max() == 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration - 2\n",
      "[13635, 56, 11, 65, 19]\n",
      "sorted logits tensor sum - -582465.75\n",
      "[0.6717739105224609, 0.13499009609222412, 0.04175287485122681, 0.02784247137606144]\n",
      "row logit tensor sum - -47.7884521484375\n",
      "Break index i - 27\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.6907], device='mps:0')\n",
      "obs surprise value - 0.5337700339256832\n",
      "indices to remove - 516106620\n",
      "sum value - 3.236032009124756\n",
      "Iteration - 3\n",
      "[5081, 7364, 128, 3, 8]\n",
      "sorted logits tensor sum - -556477.8125\n",
      "[0.7825827598571777, 0.073967345058918, 0.06892622262239456, 0.016024406999349594]\n",
      "row logit tensor sum - -28.038368225097656\n",
      "Break index i - 19\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.8048], device='mps:0')\n",
      "obs surprise value - 0.31335414644792475\n",
      "indices to remove - 516115174\n",
      "sum value - 3.9045827388763428\n",
      "Iteration - 4\n",
      "[5, 11, 21, 28, 6]\n",
      "sorted logits tensor sum - -631473.0\n",
      "[0.39131960272789, 0.24724672734737396, 0.1132679358124733, 0.08391641825437546]\n",
      "row logit tensor sum - -187.94674682617188\n",
      "Break index i - 43\n",
      "previous index - tensor([3], device='mps:0')\n",
      "logit val - tensor([0.0853], device='mps:0')\n",
      "obs surprise value - 3.5521349603478383\n",
      "indices to remove - 516120227\n",
      "sum value - 0.0\n",
      "Iteration - 5\n",
      "[16637, 3, 160, 128, 8]\n",
      "sorted logits tensor sum - -492372.75\n",
      "[0.5405165553092957, 0.05982523784041405, 0.05824319273233414, 0.033874060958623886]\n",
      "row logit tensor sum - -416.1488342285156\n",
      "Break index i - 126\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.5940], device='mps:0')\n",
      "obs surprise value - 0.7515840661002513\n",
      "indices to remove - 516103618\n",
      "sum value - 2.890915870666504\n",
      "Iteration - 6\n",
      "[5, 11, 5721, 6, 21]\n",
      "sorted logits tensor sum - -651403.125\n",
      "[0.5098065137863159, 0.2621716856956482, 0.09421847015619278, 0.02814394421875477]\n",
      "row logit tensor sum - -176.40728759765625\n",
      "Break index i - 38\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.5143], device='mps:0')\n",
      "obs surprise value - 0.9594535789166547\n",
      "indices to remove - 516120250\n",
      "sum value - 0.9935876131057739\n",
      "Iteration - 7\n",
      "[21542, 16637, 1, 451, 216]\n",
      "sorted logits tensor sum - -576928.8125\n",
      "[0.3866589367389679, 0.19057472050189972, 0.16595374047756195, 0.133648082613945]\n",
      "row logit tensor sum - -190.6572723388672\n",
      "Break index i - 57\n",
      "previous index - tensor([3], device='mps:0')\n",
      "logit val - tensor([0.1364], device='mps:0')\n",
      "obs surprise value - 2.873770851047545\n",
      "indices to remove - 516119804\n",
      "sum value - 1.6822972297668457\n",
      "Iteration - 8\n",
      "[56, 31, 19, 2746, 65]\n",
      "sorted logits tensor sum - -617016.0625\n",
      "[0.6816494464874268, 0.17933018505573273, 0.023807231336832047, 0.018710236996412277]\n",
      "row logit tensor sum - -327.373779296875\n",
      "Break index i - 72\n",
      "previous index - tensor([4], device='mps:0')\n",
      "logit val - tensor([0.0103], device='mps:0')\n",
      "obs surprise value - 6.601596697549041\n",
      "indices to remove - 516120190\n",
      "sum value - 0.0\n",
      "Iteration - 9\n",
      "[12, 3, 29, 150, 641]\n",
      "sorted logits tensor sum - -497524.15625\n",
      "[0.11059985309839249, 0.09525996446609497, 0.06570269167423248, 0.056367967277765274]\n",
      "row logit tensor sum - -1048.867431640625\n",
      "Break index i - 254\n",
      "previous index - tensor([38], device='mps:0')\n",
      "logit val - tensor([0.0043], device='mps:0')\n",
      "obs surprise value - 7.8598564267678865\n",
      "indices to remove - 516119825\n",
      "sum value - 0.0\n",
      "Iteration - 10\n",
      "[80, 2696, 7364, 5721, 800]\n",
      "sorted logits tensor sum - -379825.78125\n",
      "[0.13595105707645416, 0.09515073895454407, 0.08468548953533173, 0.04890875518321991]\n",
      "row logit tensor sum - -12.097142219543457\n",
      "Break index i - 236\n",
      "previous index - tensor([36], device='mps:0')\n",
      "logit val - tensor([0.0034], device='mps:0')\n",
      "obs surprise value - 8.217039972123732\n",
      "indices to remove - 516115971\n",
      "sum value - 1.2059237957000732\n",
      "Iteration - 11\n",
      "[5, 11, 6, 5721, 113]\n",
      "sorted logits tensor sum - -541954.3125\n",
      "[0.40784952044487, 0.08336398750543594, 0.06099051237106323, 0.05939466878771782]\n",
      "row logit tensor sum - -395.1547546386719\n",
      "Break index i - 107\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.4254], device='mps:0')\n",
      "obs surprise value - 1.2332121052221725\n",
      "indices to remove - 516120250\n",
      "sum value - 1.98716402053833\n",
      "Iteration - 12\n",
      "[21542, 1, 16637, 451, 216]\n",
      "sorted logits tensor sum - -586643.625\n",
      "[0.6349300146102905, 0.18252909183502197, 0.08893655240535736, 0.045419637113809586]\n",
      "row logit tensor sum - -78.47241973876953\n",
      "Break index i - 31\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.6440], device='mps:0')\n",
      "obs surprise value - 0.6348443204647893\n",
      "indices to remove - 516098713\n",
      "sum value - 3.661799669265747\n",
      "Iteration - 13\n",
      "[56, 11, 19, 31, 54]\n",
      "sorted logits tensor sum - -596377.0\n",
      "[0.8217237591743469, 0.039752598851919174, 0.03537644073367119, 0.026279136538505554]\n",
      "row logit tensor sum - -287.940673828125\n",
      "Break index i - 61\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.8332], device='mps:0')\n",
      "obs surprise value - 0.2632959463580911\n",
      "indices to remove - 516120199\n",
      "sum value - 2.2006969451904297\n",
      "Iteration - 14\n",
      "[830, 369, 1432, 240, 36]\n",
      "sorted logits tensor sum - -588807.8125\n",
      "[0.8544288277626038, 0.049206994473934174, 0.00843831431120634, 0.008194126188755035]\n",
      "row logit tensor sum - -288.3389587402344\n",
      "Break index i - 82\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.8629], device='mps:0')\n",
      "obs surprise value - 0.21273010192615313\n",
      "indices to remove - 516119425\n",
      "sum value - 3.857480525970459\n",
      "Iteration - 15\n",
      "[16637, 160, 376, 135, 34]\n",
      "sorted logits tensor sum - -587298.6875\n",
      "[0.493875116109848, 0.3353847861289978, 0.07682794332504272, 0.02120179496705532]\n",
      "row logit tensor sum - -428.34539794921875\n",
      "Break index i - 94\n",
      "previous index - tensor([1], device='mps:0')\n",
      "logit val - tensor([0.3391], device='mps:0')\n",
      "obs surprise value - 1.5600668007416378\n",
      "indices to remove - 516120095\n",
      "sum value - 2.185911178588867\n",
      "Iteration - 16\n",
      "[5721, 12, 28, 5, 6871]\n",
      "sorted logits tensor sum - -519845.21875\n",
      "[0.7465661764144897, 0.04823050647974014, 0.010975338518619537, 0.010645482689142227]\n",
      "row logit tensor sum - -1103.82568359375\n",
      "Break index i - 232\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.7629], device='mps:0')\n",
      "obs surprise value - 0.39050616944144256\n",
      "indices to remove - 516114534\n",
      "sum value - 3.166080951690674\n",
      "Iteration - 17\n",
      "[5, 12, 6, 21, 11]\n",
      "sorted logits tensor sum - -649105.625\n",
      "[0.9183662533760071, 0.02404375933110714, 0.007763959467411041, 0.00671361293643713]\n",
      "row logit tensor sum - -317.4534606933594\n",
      "Break index i - 57\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.9209], device='mps:0')\n",
      "obs surprise value - 0.1189318884761007\n",
      "indices to remove - 516120250\n",
      "sum value - 2.195949077606201\n",
      "Iteration - 18\n",
      "[1, 16637, 451, 21542, 328]\n",
      "sorted logits tensor sum - -682306.75\n",
      "[0.9892261624336243, 0.002041782485321164, 0.0012168436078354716, 0.001125452108681202]\n",
      "row logit tensor sum - -217.8433074951172\n",
      "Break index i - 28\n",
      "previous index - tensor([0], device='mps:0')\n",
      "logit val - tensor([0.9924], device='mps:0')\n",
      "obs surprise value - 0.011059317421468299\n"
     ]
    }
   ],
   "source": [
    "# Earlier\n",
    "from llmsearch.utils.model_utils import seed_everything\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "parameters and how they affect do_sample == False\n",
    "1. temperature - output does not change - greedy decoding\n",
    "2. top_k - output does not change - greedy decoding\n",
    "3. repetition_penalty - output changes\n",
    "4. no_repeat_ngram_size - output changes\n",
    "\"\"\"\n",
    "\n",
    "# seed_everything(seed)\n",
    "\n",
    "initial_generation_params1 = {\n",
    "    'max_new_tokens' : 120,\n",
    "#     'repetition_penalty'  : 0.6,\n",
    "#     'repetition_penalty_range'  : 5,\n",
    "#     'temperature' : 0.7,\n",
    "    'do_sample' : True,\n",
    "    'generation_seed' : 42,\n",
    "    'mirostat_mode': 2,\n",
    "    'mirostat_tau' : 5,\n",
    "#     'top_a' : 0.1,\n",
    "}\n",
    "score, outputs1 = tuner_ob.get_score(initial_generation_params1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15473f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14664d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amanda baked cookies with Jerry. She has another brother. Amanda will bring her tomorrow.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ac45f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amanda baked cookies. Jerry will bring Amanda tomorrow.',\n",
       " 'Olivia is voting for Liberals.',\n",
       " \"Kim is going to do a lot of stuff but she's procrastinating. Kim will move her ass and do everything. Tim recommends Pomodoro technique where she uses breaks for doing chores.\",\n",
       " 'Edward is in ove with Rachel.',\n",
       " \"Sam is worried about rick saying something to her roommate. He told them that he didn't like being her roommate. Sam is worried about him.\",\n",
       " 'Neville got married on September 17. Wyatt will ask her wife to check on her wedding anniversary.',\n",
       " 'Cassandra will check the homework for John in 20 minutes. John will check it for him in 20 minutes. Cassandra will go to his boss to help him. John will help him with his homework.',\n",
       " \"James found a song on youtube. He doesn't like it. He listens to it everytime he listens to it.\",\n",
       " 'Noah quit his job and quit his job. Madison thinks Noah liked it.',\n",
       " 'Matt and Agnes are going to the Georgian restaurant in Kazimierz on Saturday at 6 pm. Matt will pick Agnes up on the way to the restaurant.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0653ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for y_t, y_p in zip(tuner_ob.dataset['y'], outputs1):\n",
    "    print(y_p)\n",
    "    print(y_t,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745852b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22995afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_param_grid = {\n",
    "    \"max_new_tokens\": [120],\n",
    "    \"temperature\": list(np.linspace(start=0.1, stop=1.0,num=10)),\n",
    "    'top_k' : list(map(int,np.linspace(start=10, stop=50,num=5))),\n",
    "    \"top_p\": [0.75, 0.8, 0.9, 1.0],\n",
    "    'do_sample' : [True, False],\n",
    "    'generation_seed' : [42],\n",
    "    'repetition_penalty' : [1.0, 1.2],\n",
    "    'no_repeat_ngram_size' : [0,2,3],\n",
    "}\n",
    "\n",
    "hyp_param_grid_2= {\n",
    "    \"max_new_tokens\": [120],\n",
    "    \"temperature\": list(np.linspace(start=0.1, stop=1.0,num=10000)),\n",
    "    'top_k' : list(map(int,np.linspace(start=10, stop=50,num=5000))),\n",
    "    \"top_p\": list(map(int,np.linspace(start=10, stop=50,num=5000))),\n",
    "    'do_sample' : [True],\n",
    "    'generation_seed' : [42],\n",
    "    'num_beams' : [1],\n",
    "#     'repetition_penalty' : [1.0, 1.2],\n",
    "#     'no_repeat_ngram_size' : [0,2,3],\n",
    "}\n",
    "\n",
    "scorer = make_scorer(score_func=get_rouge_score, greater_is_better=True)\n",
    "\n",
    "\n",
    "clf = RandomizedSearchCV(\n",
    "    estimator=tuner_ob.estimator,\n",
    "    param_distributions=hyp_param_grid_2,\n",
    "    n_iter = 2,\n",
    "    scoring=scorer,\n",
    "    cv=5,\n",
    "    random_state = 42,\n",
    "    n_jobs=None,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "5 fold means, whole sample set of 100 examples will be split into 80:20 ratio\n",
    "for each hyper_parameter set we have a model f(hyper_params)\n",
    "    - we will evaluate this model and get the cross val score (test on each 20 samples 5 times, while training on the rest 80 each time)\n",
    "    - we get the score on the quality of hyperparams by evaluating the model with the hyperparams on the unseen 1 fold\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f070d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 = 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967d672",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.fit(X=tuner_ob.dataset[\"X\"], y=tuner_ob.dataset[\"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a41bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e8919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e1269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.best_estimator_.set_params(**clf.best_params_).get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11bd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c02681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "clone(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee361ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a846cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d9506",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f27049",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
