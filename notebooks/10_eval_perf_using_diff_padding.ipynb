{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monkey Patching .generate function of `transformers` library\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Check how the model pads input\n",
    "Check how different enecoding & decoding params affect the encoding & decoding\n",
    "check performance of model on a sample set at different batch sizes (inadvertently check how the model performs when padding is present)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Autocompletion\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "# Autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/workspace/llmsearch')\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "import ctypes\n",
    "import json\n",
    "import nltk\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import evaluate\n",
    "import datasets\n",
    "import langchain\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from transformers import GPTQConfig, BitsAndBytesConfig\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "from transformers import PreTrainedModel, PretrainedConfig, GenerationConfig, StoppingCriteria, AutoTokenizer, StoppingCriteriaList, AutoModel, AutoModelForCausalLM\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import ctypes\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional, Union, List\n",
    "\n",
    "import time\n",
    "import textwrap\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from exllamav2 import (\n",
    "    ExLlamaV2,\n",
    "    ExLlamaV2Cache,\n",
    "    ExLlamaV2Cache_8bit,\n",
    "    ExLlamaV2Config\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from llmsearch.model_downloader import download_model_from_hf\n",
    "from llmsearch.utils.model_utils import batcher, decoder_parser\n",
    "\n",
    "import awq\n",
    "\n",
    "from awq import AutoAWQForCausalLM\n",
    "\n",
    "def pretty_print_dict(d, indent = 4):\n",
    "    print(json.dumps(d, indent = indent, default = str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.2.0+cu121', '0.2.4')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsm8k_dataset = load_dataset(\"gsm8k\", 'main')\n",
    "\n",
    "torch.__version__, awq.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def seed_everything(seed):\n",
    "    \"\"\"Seed for reproducibilty\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "class SingleTokenStoppingCriteria(StoppingCriteria):\n",
    "    \"\"\"End generation if end token is encountered\n",
    "    does not support batched implementation yet\"\"\"\n",
    "\n",
    "    def __init__(self, token_id):\n",
    "      super().__init__()\n",
    "      self.token_id =  token_id\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\n",
    "        res = []\n",
    "\n",
    "        last_token_id = input_ids[0][-1]\n",
    "        if last_token_id == self.token_id:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "def cm():\n",
    "    gc.collect()\n",
    "    ctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def seed_everything(seed):\n",
    "    \"\"\"Seed for reproducibilty\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "\n",
    "def perform_single_example_inference(example, model, tokenizer,gen_kwargs):\n",
    "\n",
    "    tokenized_input = tokenizer(example, return_tensors = \"pt\", add_special_tokens = False)\n",
    "    tokenized_input['input_ids'] = tokenized_input['input_ids'].to('cuda:0')\n",
    "\n",
    "    tokenized_input['attention_mask'] = tokenized_input['attention_mask'].to('cuda:0')\n",
    "    # tokenized_input.to(device)\n",
    "    # print(tokenized_input)\n",
    "\n",
    "    model_out = model.generate(**tokenized_input, **gen_kwargs)\n",
    "    prompt_tokens = len(tokenized_input['input_ids'][0])\n",
    "    print(f\"Prompt tokens - {prompt_tokens}\")\n",
    "    # print(model_out.tolist()[0])\n",
    "\n",
    "    output_token_ids = model_out.tolist()[0]\n",
    "    decoded_output = tokenizer.decode(output_token_ids, spaces_between_special_tokens = False)\n",
    "\n",
    "    print(decoded_output)\n",
    "    completion_tokens = len(output_token_ids) - prompt_tokens\n",
    "\n",
    "    print(f\"Completion Tokens - {completion_tokens}\")\n",
    "\n",
    "    return decoded_output, prompt_tokens, completion_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaders\n",
    "\n",
    "class MultiTokenEOSCriteria(transformers.StoppingCriteria):\n",
    "    \"\"\"Criteria to stop on the specified multi-token sequence.\n",
    "\n",
    "    This code is not thread safe. The same object cannot be used simultaneously in multiple threads.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sequence_ids : List[int],\n",
    "    ) -> None:\n",
    "        self.sequence_ids = torch.tensor(sequence_ids, dtype = torch.int32, device = \"cuda:0\")\n",
    "        # we look back for 2 more tokens than it takes to encode our stop sequence\n",
    "        # because tokenizers suck, and a model might generate `['\\n', '\\n']` but our `sequence` is `['\\n\\n']`\n",
    "        # and we don't want to mistakenly not stop a generation because our\n",
    "        # (string) stop sequence was output in a different tokenization\n",
    "        # NOTE: there is a minor danger that this will end up looking back 2 tokens into the past, into the inputs to the model,\n",
    "        # and stopping generation immediately as a result. With only 2 extra tokens of lookback, this risk is minimized\n",
    "        # Additionally, in lookback_ids_batch we should prevent ever looking back into the inputs as described.\n",
    "        self.sequence_id_len = self.sequence_ids.shape[0] + 2\n",
    "        self.state_initialized = False\n",
    "        self.input_length = None\n",
    "        self.state_initialized = False\n",
    "\n",
    "    def set_state(self, batch_size, input_length):\n",
    "        self.batch_size = batch_size\n",
    "        self.input_length = input_length\n",
    "        self.done_tracker = [False] * batch_size\n",
    "        self.state_initialized = True\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_size = None\n",
    "        self.input_length = None\n",
    "        self.state_initialized = False\n",
    "\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs) -> bool:\n",
    "        # For efficiency, we compare the last n tokens where n is the number of tokens in the stop_sequence\n",
    "\n",
    "        ret_val = False\n",
    "\n",
    "        if not self.state_initialized:\n",
    "            # 1st call to __call__ for this batch\n",
    "            self.set_state(input_ids.shape[0], input_ids.shape[1])\n",
    "\n",
    "        # IDs of all the tokens except the prompt\n",
    "        lookback_ids_batch = input_ids[:, self.input_length :]\n",
    "        # look back for 2 more tokens than it takes to encode our stop sequence\n",
    "        lookback_ids_batch = lookback_ids_batch[:, -self.sequence_id_len :]\n",
    "\n",
    "        # no elements yet to look back\n",
    "        if lookback_ids_batch.nelement() == 0:\n",
    "            return False\n",
    "\n",
    "        for i, done in enumerate(self.done_tracker):\n",
    "            if not done:\n",
    "                # look back only as far as the last token of the stop sequence\n",
    "                self.done_tracker[i] = self.sequence_ids == lookback_ids_batch[i][-(self.sequence_ids.shape[0]):]\n",
    "        ret_val = False not in self.done_tracker\n",
    "        if ret_val:\n",
    "            # print(f\"finish, \", self.sequence_ids, lookback_ids_batch)\n",
    "            self.reset()\n",
    "        return ret_val\n",
    "\n",
    "\n",
    "def load_model_with_awq_backend(model_id, model_loader_kwargs, tokenizer_kwargs,temp_model_dir, model_branch = \"main\"):\n",
    "    output_folder = download_model_from_hf(model_id, save_dir = temp_model_dir, branch = model_branch)\n",
    "\n",
    "    model_loader_kwargs['pretrained_model_name_or_path'] = output_folder\n",
    "    tokenizer_loader_kwargs['pretrained_model_name_or_path'] = output_folder\n",
    "\n",
    "    model_name_or_path = model_loader_kwargs.pop('pretrained_model_name_or_path')\n",
    "    model = AutoAWQForCausalLM.from_quantized(\n",
    "        quant_path=model_name_or_path,\n",
    "        **model_loader_kwargs\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(**tokenizer_kwargs, local_files_only=True)\n",
    "\n",
    "    # pad token is null in config -https://huggingface.co/TheBloke/CapybaraHermes-2.5-Mistral-7B-AWQ/blob/eb64c310c44905321d012962db9ac0d47c3a64fa/tokenizer_config.json#L53\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "model_loader_backend_map = {\n",
    "    # \"exllama_2_hf\": load_model_with_exllama_2_hf_backend,\n",
    "    # \"hf\": load_model_with_hf_backend,\n",
    "    # 'auto_gptq' : load_model_with_autogptq_backend,\n",
    "    'awq' : load_model_with_awq_backend,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the model to /workspace/temp_model_dir/TheBloke_CapybaraHermes-2.5-Mistral-7B-AWQ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17.9k /17.9k  30.3MiB/s\n",
      "100%|██████████| 51.0  /51.0   104kiB/s\n",
      "100%|██████████| 126   /126    351kiB/s\n",
      "100%|██████████| 420   /420    786kiB/s\n",
      "100%|██████████| 1.80M /1.80M  3.33MiB/s\n",
      "100%|██████████| 493k  /493k   76.3MiB/s\n",
      "100%|██████████| 1.60k /1.60k  3.58MiB/s\n",
      "100%|██████████| 911   /911    2.24MiB/s\n",
      "100%|██████████| 115   /115    60.6kiB/s\n",
      "100%|██████████| 4.15G /4.15G  199MiB/s \n",
      "Replacing layers...: 100%|██████████| 32/32 [00:04<00:00,  7.38it/s]\n",
      "Fusing layers...: 100%|██████████| 32/32 [00:02<00:00, 11.94it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/TheBloke/CapybaraHermes-2.5-Mistral-7B-AWQ\n",
    "model_id = \"TheBloke/CapybaraHermes-2.5-Mistral-7B-AWQ\"\n",
    "\n",
    "temp_model_dir = Path(f\"/workspace/temp_model_dir/\")\n",
    "temp_model_dir.mkdir(exist_ok = True, parents = True)\n",
    "\n",
    "model_loader_kwargs = {\n",
    "    'device_map' : {'' : 0},\n",
    "    'fuse_layers' : True,\n",
    "}\n",
    "\n",
    "tokenizer_loader_kwargs = {\n",
    "    'use_fast' : False,\n",
    "    'legacy' : False,\n",
    "    'padding_side' : 'left',\n",
    "}\n",
    "\n",
    "model, tokenizer = load_model_with_awq_backend(model_id, model_loader_kwargs, tokenizer_loader_kwargs,temp_model_dir, model_branch = \"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset, tokenizer, pt, pt_cols, system_prompt, add_generation_prompt = True):\n",
    "\n",
    "    def wrapper(sample):\n",
    "        \"\"\"Takes in a sample, formats it using prompt template, applies chat template and returns the formatted string\"\"\"\n",
    "        messages = [] if system_prompt is None else [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "        formatted_pt = pt.format(**{pt_col : sample[pt_col] for pt_col in pt_cols})\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": formatted_pt,\n",
    "            }\n",
    "        )\n",
    "        formatted_pt_with_ct = tokenizer.apply_chat_template(messages, tokenize = False, add_generation_prompt=add_generation_prompt)\n",
    "        return formatted_pt_with_ct\n",
    "\n",
    "    def actual_input(sample):\n",
    "        \"\"\"Takes in a sample, formats it using prompt template, applies chat template and returns the formatted string\"\"\"\n",
    "        return sample[pt_cols[0]]\n",
    "\n",
    "\n",
    "\n",
    "    pt_dataset = dataset.map(\n",
    "        lambda sample : {\n",
    "            \"X\" : wrapper(sample),\n",
    "            'actual input' : actual_input(sample),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return pt_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2e0123e31d43e49e86cb0a69ae6564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pt = textwrap.dedent(\"\"\"\\\n",
    "    Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
    "    A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
    "\n",
    "    Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
    "    A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
    "\n",
    "    Q: {question}\"\"\")\n",
    "pt_cols = ['question']\n",
    "system_prompt = \"Solve the following math problems, end with The answer is\"\n",
    "\n",
    "# Add prompt template\n",
    "processed_dataset = preprocess_dataset(gsm8k_dataset['train'], tokenizer,pt = pt, pt_cols = pt_cols, system_prompt = system_prompt, add_generation_prompt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "bm_sample_size = 50\n",
    "bm_samples = processed_dataset.shuffle(seed = seed).select(range(bm_sample_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Mimi picked up 2 dozen seashells on the beach.  Kyle found twice as many shells as Mimi and put them in his pocket. Leigh grabbed one-third of the shells that Kyle found.  How many seashells did Leigh have?',\n",
       " 'answer': 'Mimi has 2 x 12 = <<2*12=24>>24 sea shells.\\nKyle has 24 x 2 = <<24*2=48>>48 sea shells.\\nLeigh has 48 / 3 = <<48/3=16>>16 sea shells.\\n#### 16',\n",
       " 'X': '<|im_start|>system\\nSolve the following math problems, end with The answer is<|im_end|>\\n<|im_start|>user\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\n\\nQ: Mimi picked up 2 dozen seashells on the beach.  Kyle found twice as many shells as Mimi and put them in his pocket. Leigh grabbed one-third of the shells that Kyle found.  How many seashells did Leigh have?<|im_end|>\\n<|im_start|>assistant\\n',\n",
       " 'actual input': 'Mimi picked up 2 dozen seashells on the beach.  Kyle found twice as many shells as Mimi and put them in his pocket. Leigh grabbed one-third of the shells that Kyle found.  How many seashells did Leigh have?'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_answer_from_out(s):\n",
    "    pattern = re.compile(r\"The answer is (\\d+(?:\\.\\d+)?)\")\n",
    "    match = pattern.search(s)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_score(y_true, y_pred):\n",
    "    scores = []\n",
    "\n",
    "    for y_t, y_p in zip(y_true, y_pred):\n",
    "        y_t_answer = y_t['answer'].split(\"####\")[-1].strip()\n",
    "        y_p_answer = extract_answer_from_out(y_p)\n",
    "\n",
    "\n",
    "        if y_t_answer == y_p_answer:\n",
    "            scores.append(1)\n",
    "        else:\n",
    "            scores.append(0)\n",
    "    return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmsearch.utils.logging_utils import set_verbosity_info, set_verbosity_debug, set_verbosity_warning\n",
    "set_verbosity_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_size_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbatch_size_list\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_size_list' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size - 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64eb17162aa440e18d08db5f8e43c49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting state - (16, 298)\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 1])\n",
      "seq len - torch.Size([16, 299]), prompt len - 298\n",
      "torch.Size([16, 2])\n",
      "seq len - torch.Size([16, 300]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 301]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 302]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 303]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 304]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 305]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 306]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 307]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 308]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 309]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 310]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 311]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 312]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 313]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 314]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 315]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 316]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 317]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 318]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 319]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 320]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 321]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 322]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 323]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 324]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 325]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 326]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 327]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 328]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 329]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 330]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 331]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 332]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 333]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 334]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 335]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 336]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 337]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 338]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 339]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 340]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 341]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 342]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 343]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 344]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 345]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 346]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 347]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 348]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 349]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 350]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 351]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 352]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 353]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 354]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 355]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 356]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 357]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 358]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 359]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 360]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 361]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 362]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 363]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 364]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 365]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 366]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 367]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 368]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 369]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 370]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 371]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 372]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 373]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 374]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 375]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 376]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 377]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 378]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 379]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 380]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 381]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 382]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 383]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 384]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 385]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 386]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 387]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 388]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 389]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 390]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 391]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 392]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 393]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 394]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 395]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 396]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 397]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 398]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 399]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 400]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 401]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 402]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 403]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 404]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 405]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 406]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 407]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 408]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 409]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 410]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 411]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 412]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 413]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 414]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 415]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 416]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 417]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 418]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 419]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 420]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 421]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 422]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 423]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 424]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 425]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 426]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 427]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 428]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 429]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 430]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 431]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 432]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 433]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 434]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 435]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 436]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 437]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 438]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 439]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 440]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 441]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 442]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 443]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 444]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 445]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 446]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 447]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 448]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 449]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 450]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 451]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 452]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 453]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 454]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 455]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 456]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 457]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 458]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 459]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 460]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 461]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 462]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 463]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 464]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 465]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 466]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 467]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 468]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 469]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 470]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 471]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 472]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 473]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 474]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 475]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 476]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 477]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 478]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 479]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 480]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 481]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 482]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 483]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 484]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 485]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 486]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 487]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 488]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 489]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 490]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 491]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 492]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 493]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 494]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 495]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 496]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 497]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 498]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 499]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 500]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 501]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 502]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 503]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 504]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 505]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 506]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 507]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 508]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 509]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 510]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 511]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 512]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 513]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 514]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 515]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 516]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 517]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 518]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 519]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 520]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 521]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 522]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 523]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 524]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 525]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 526]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 527]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 528]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 529]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 530]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 531]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 532]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 533]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 534]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 535]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 536]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 537]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 538]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 539]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 540]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 541]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 542]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 543]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 544]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 545]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 546]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 547]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 548]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 549]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 550]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 551]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 552]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 553]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 554]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 555]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 556]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 557]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 558]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 559]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 560]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 561]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 562]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 563]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 564]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 565]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 566]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 567]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 568]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 569]), prompt len - 298\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 1])\n",
      "seq len - torch.Size([16, 299]), prompt len - 298\n",
      "torch.Size([16, 2])\n",
      "seq len - torch.Size([16, 300]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 301]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 302]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 303]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 304]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 305]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 306]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 307]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 308]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 309]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 310]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 311]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 312]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 313]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 314]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 315]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 316]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 317]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 318]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 319]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 320]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 321]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 322]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 323]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 324]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 325]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 326]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 327]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 328]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 329]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 330]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 331]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 332]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 333]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 334]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 335]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 336]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 337]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 338]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 339]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 340]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 341]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 342]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 343]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 344]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 345]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 346]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 347]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 348]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 349]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 350]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 351]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 352]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 353]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 354]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 355]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 356]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 357]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 358]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 359]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 360]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 361]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 362]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 363]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 364]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 365]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 366]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 367]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 368]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 369]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 370]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 371]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 372]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 373]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 374]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 375]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 376]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 377]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 378]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 379]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 380]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 381]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 382]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 383]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 384]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 385]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 386]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 387]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 388]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 389]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 390]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 391]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 392]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 393]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 394]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 395]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 396]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 397]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 398]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 399]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 400]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 401]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 402]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 403]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 404]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 405]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 406]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 407]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 408]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 409]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 410]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 411]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 412]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 413]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 414]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 415]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 416]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 417]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 418]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 419]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 420]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 421]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 422]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 423]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 424]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 425]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 426]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 427]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 428]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 429]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 430]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 431]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 432]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 433]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 434]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 435]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 436]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 437]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 438]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 439]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 440]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 441]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 442]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 443]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 444]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 445]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 446]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 447]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 448]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 449]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 450]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 451]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 452]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 453]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 454]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 455]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 456]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 457]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 458]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 459]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 460]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 461]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 462]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 463]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 464]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 465]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 466]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 467]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 468]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 469]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 470]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 471]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 472]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 473]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 474]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 475]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 476]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 477]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 478]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 479]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 480]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 481]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 482]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 483]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 484]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 485]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 486]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 487]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 488]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 489]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 490]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 491]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 492]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 493]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 494]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 495]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 496]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 497]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 498]), prompt len - 298\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 0])\n",
      "torch.Size([16, 1])\n",
      "seq len - torch.Size([16, 299]), prompt len - 298\n",
      "torch.Size([16, 2])\n",
      "seq len - torch.Size([16, 300]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 301]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 302]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 303]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 304]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 305]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 306]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 307]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 308]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 309]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 310]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 311]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 312]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 313]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 314]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 315]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 316]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 317]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 318]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 319]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 320]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 321]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 322]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 323]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 324]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 325]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 326]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 327]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 328]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 329]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 330]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 331]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 332]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 333]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 334]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 335]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 336]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 337]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 338]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 339]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 340]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 341]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 342]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 343]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 344]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 345]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 346]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 347]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 348]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 349]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 350]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 351]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 352]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 353]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 354]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 355]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 356]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 357]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 358]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 359]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 360]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 361]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 362]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 363]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 364]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 365]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 366]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 367]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 368]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 369]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 370]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 371]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 372]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 373]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 374]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 375]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 376]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 377]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 378]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 379]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 380]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 381]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 382]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 383]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 384]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 385]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 386]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 387]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 388]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 389]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 390]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 391]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 392]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 393]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 394]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 395]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 396]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 397]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 398]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 399]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 400]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 401]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 402]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 403]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 404]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 405]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 406]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 407]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 408]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 409]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 410]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 411]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 412]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 413]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 414]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 415]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 416]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 417]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 418]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 419]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 420]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 421]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 422]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 423]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 424]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 425]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 426]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 427]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 428]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 429]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 430]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 431]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 432]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 433]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 434]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 435]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 436]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 437]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 438]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 439]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 440]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 441]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 442]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 443]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 444]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 445]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 446]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 447]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 448]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 449]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 450]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 451]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 452]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 453]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 454]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 455]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 456]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 457]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 458]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 459]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 460]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 461]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 462]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 463]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 464]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 465]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 466]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 467]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 468]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 469]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 470]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 471]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 472]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 473]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 474]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 475]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 476]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 477]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 478]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 479]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 480]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 481]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 482]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 483]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 484]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 485]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 486]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 487]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 488]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 489]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 490]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 491]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 492]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 493]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 494]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 495]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 496]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 497]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 498]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 499]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 500]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 501]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 502]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 503]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 504]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 505]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 506]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 507]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 508]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 509]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 510]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 511]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 512]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 513]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 514]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 515]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 516]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 517]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 518]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 519]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 520]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 521]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 522]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 523]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 524]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 525]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 526]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 527]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 528]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 529]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 530]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 531]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 532]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 533]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 534]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 535]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 536]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 537]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 538]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 539]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 540]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 541]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 542]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 543]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 544]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 545]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 546]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 547]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 548]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 549]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 550]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 551]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 552]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 553]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 554]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 555]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 556]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 557]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 558]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 559]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 560]), prompt len - 298\n",
      "torch.Size([16, 3])\n",
      "seq len - torch.Size([16, 561]), prompt len - 298\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 0])\n",
      "torch.Size([2, 1])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 6 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 111\u001b[0m\n\u001b[1;32m    104\u001b[0m gen_params1 \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_new_tokens\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstopping_criteria\u001b[39m\u001b[38;5;124m'\u001b[39m : stopping_criteria,\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneration_seed\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m    108\u001b[0m }\n\u001b[1;32m    110\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 111\u001b[0m scores, outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtuner_ob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_params1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    114\u001b[0m score_at_diff_batch_sizes[batch_size] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m : scores,\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m : outputs,\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimal_batch_size\u001b[39m\u001b[38;5;124m'\u001b[39m : tuner_ob\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39m_optimal_batch_size,\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatency_mins\u001b[39m\u001b[38;5;124m'\u001b[39m : (end  \u001b[38;5;241m-\u001b[39m start) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m,\n\u001b[1;32m    119\u001b[0m }\n",
      "File \u001b[0;32m/workspace/llmsearch/llmsearch/tuner/tuner.py:371\u001b[0m, in \u001b[0;36mTuner.get_score\u001b[0;34m(self, generation_kwargs, dataset)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate the score function on a dataset or the initialized dataset using some generation arguments for the model\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;124;03m    Tuple[float, List]: score, predictions\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    370\u001b[0m dataset_to_evaluate \u001b[38;5;241m=\u001b[39m dataset \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\n\u001b[0;32m--> 371\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43minfer_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_encoder_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_encoder_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimal_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_to_evaluate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_encoding_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer_encoding_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_decoding_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer_decoding_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_batch_size_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_batch_size_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_generation_param_checks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_generation_param_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_preproc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_preproc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscore_func(\n\u001b[1;32m    386\u001b[0m     y_true\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m], y_pred\u001b[38;5;241m=\u001b[39my_pred\n\u001b[1;32m    387\u001b[0m )\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score, y_pred\n",
      "File \u001b[0;32m/workspace/llmsearch/llmsearch/utils/mem_utils.py:162\u001b[0m, in \u001b[0;36mbatch_without_oom_error.<locals>.inner_wrapper\u001b[0;34m(batch_size, disable_batch_size_cache, *args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# Try running with specified batch size\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_batch_size_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_batch_size_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m         gc_cuda()\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m disable_batch_size_cache:\n",
      "File \u001b[0;32m/workspace/llmsearch/llmsearch/utils/model_utils.py:116\u001b[0m, in \u001b[0;36minfer_data\u001b[0;34m(model, tokenizer, is_encoder_decoder, batch_size, disable_batch_size_cache, device, model_inputs, tokenizer_encoding_kwargs, generation_kwargs, disable_generation_param_checks, tokenizer_decoding_kwargs, return_optimal_batch_size, output_preproc)\u001b[0m\n\u001b[1;32m    114\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m encoded_input\u001b[38;5;241m.\u001b[39minput_ids\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    115\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m encoded_input\u001b[38;5;241m.\u001b[39mattention_mask\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 116\u001b[0m output_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_kwargs\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m decoded_output \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m    120\u001b[0m     sequences\u001b[38;5;241m=\u001b[39moutput_ids,\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_decoding_kwargs,\n\u001b[1;32m    122\u001b[0m )\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# remove prompt\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/awq/models/base.py:111\u001b[0m, in \u001b[0;36mBaseAWQForCausalLM.generate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A generate function that mimics the HF generate function.\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1544\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1527\u001b[0m         input_ids,\n\u001b[1;32m   1528\u001b[0m         candidate_generator\u001b[38;5;241m=\u001b[39mcandidate_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1541\u001b[0m     )\n\u001b[1;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1543\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:2467\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2464\u001b[0m         this_peer_finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2466\u001b[0m \u001b[38;5;66;03m# stop if we exceed the maximum length\u001b[39;00m\n\u001b[0;32m-> 2467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mstopping_criteria\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2468\u001b[0m     this_peer_finished \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m this_peer_finished \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m synced_gpus:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/stopping_criteria.py:132\u001b[0m, in \u001b[0;36mStoppingCriteriaList.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;129m@add_start_docstrings\u001b[39m(STOPPING_CRITERIA_INPUTS_DOCSTRING)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor, scores: torch\u001b[38;5;241m.\u001b[39mFloatTensor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcriteria\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcriteria\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/stopping_criteria.py:132\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;129m@add_start_docstrings\u001b[39m(STOPPING_CRITERIA_INPUTS_DOCSTRING)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor, scores: torch\u001b[38;5;241m.\u001b[39mFloatTensor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[43mcriteria\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m criteria \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 67\u001b[0m, in \u001b[0;36mMultiTokenEOSCriteria.__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, done \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone_tracker):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;66;03m# look back only as far as the last token of the stop sequence\u001b[39;00m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;66;03m# print(len(self.done_tracker), lookback_ids_batch.shape, self.batch_size, self.input_length)\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone_tracker[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_ids \u001b[38;5;241m==\u001b[39m \u001b[43mlookback_ids_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m-\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):]\n\u001b[1;32m     68\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone_tracker\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseq len - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_ids\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, prompt len - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "from llmsearch.tuner import Tuner\n",
    "\n",
    "# TODO : bs = 16 error, figure this out\n",
    "\n",
    "# TODO : run llmsearch\n",
    "\n",
    "class MultiTokenEOSCriteria(transformers.StoppingCriteria):\n",
    "    \"\"\"Criteria to stop on the specified multi-token sequence.\n",
    "\n",
    "    This code is not thread safe. The same object cannot be used simultaneously in multiple threads.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sequence_ids : List[int],\n",
    "    ) -> None:\n",
    "        self.sequence_ids = torch.tensor(sequence_ids, dtype = torch.int32, device = \"cuda:0\")\n",
    "        # we look back for 2 more tokens than it takes to encode our stop sequence\n",
    "        # because tokenizers suck, and a model might generate `['\\n', '\\n']` but our `sequence` is `['\\n\\n']`\n",
    "        # and we don't want to mistakenly not stop a generation because our\n",
    "        # (string) stop sequence was output in a different tokenization\n",
    "        # NOTE: there is a minor danger that this will end up looking back 2 tokens into the past, into the inputs to the model,\n",
    "        # and stopping generation immediately as a result. With only 2 extra tokens of lookback, this risk is minimized\n",
    "        # Additionally, in lookback_ids_batch we should prevent ever looking back into the inputs as described.\n",
    "        self.sequence_id_len = self.sequence_ids.shape[0] + 2\n",
    "        self.state_initialized = False\n",
    "        self.input_length = None\n",
    "        self.state_initialized = False\n",
    "\n",
    "    def set_state(self, batch_size, input_length):\n",
    "        self.batch_size = batch_size\n",
    "        self.input_length = input_length\n",
    "        self.done_tracker = [False] * batch_size\n",
    "        self.state_initialized = True\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_size = None\n",
    "        self.input_length = None\n",
    "        self.state_initialized = False\n",
    "\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs) -> bool:\n",
    "        # For efficiency, we compare the last n tokens where n is the number of tokens in the stop_sequence\n",
    "\n",
    "        ret_val = False\n",
    "\n",
    "        if not self.state_initialized:\n",
    "            # 1st call to __call__ for this batch\n",
    "            print(f\"Setting state - {input_ids.shape[0], input_ids.shape[1]}\")\n",
    "            self.set_state(input_ids.shape[0], input_ids.shape[1])\n",
    "\n",
    "        # IDs of all the tokens except the prompt\n",
    "        lookback_ids_batch = input_ids[:, self.input_length :]\n",
    "        # look back for 2 more tokens than it takes to encode our stop sequence\n",
    "        lookback_ids_batch = lookback_ids_batch[:, -self.sequence_id_len :]\n",
    "\n",
    "        print(lookback_ids_batch.shape)\n",
    "\n",
    "        # no elements yet to look back\n",
    "        if lookback_ids_batch.nelement() == 0:\n",
    "            return False\n",
    "\n",
    "        for i, done in enumerate(self.done_tracker):\n",
    "            if not done:\n",
    "                # look back only as far as the last token of the stop sequence\n",
    "                # print(len(self.done_tracker), lookback_ids_batch.shape, self.batch_size, self.input_length)\n",
    "                self.done_tracker[i] = self.sequence_ids == lookback_ids_batch[i][-(self.sequence_ids.shape[0]):]\n",
    "        ret_val = False not in self.done_tracker\n",
    "        print(f'seq len - {input_ids.shape}, prompt len - {self.input_length}')\n",
    "        if ret_val:\n",
    "            self.reset()\n",
    "        return ret_val\n",
    "\n",
    "\n",
    "batch_size_list = [1, 2, 4, 8, 16, 32, 64]\n",
    "batch_size_list = [16, 32, 64]\n",
    "\n",
    "score_at_diff_batch_sizes = {}\n",
    "\n",
    "for batch_size in batch_size_list:\n",
    "    print(f\"Batch Size - {batch_size}\")\n",
    "\n",
    "    cm()\n",
    "\n",
    "    tuner_ob = Tuner(\n",
    "        model = model,\n",
    "        tokenizer = tokenizer,\n",
    "        dataset = bm_samples,\n",
    "        device = 'cuda:0',\n",
    "        batch_size = batch_size,\n",
    "        tokenizer_encoding_kwargs={'padding': 'longest', 'add_special_tokens' : False},\n",
    "        tokenizer_decoding_kwargs={'spaces_between_special_tokens' : False},\n",
    "        scorer = get_score,\n",
    "        prompt_template = langchain.PromptTemplate.from_template(\"{X}\"),\n",
    "        is_encoder_decoder = False,\n",
    "        seed = seed,\n",
    "        column_mapping = {'input_cols' : [\"X\"],'eval_cols' : ['answer']},\n",
    "    )\n",
    "\n",
    "\n",
    "    # is stopping criteria cache not being reset properly?\n",
    "    # check if reset condition is working properly\n",
    "    stopping_criteria = StoppingCriteriaList([MultiTokenEOSCriteria(sequence_ids = [32000])])\n",
    "\n",
    "    gen_params1 = {\n",
    "        'max_new_tokens' : 500,\n",
    "        'stopping_criteria' : stopping_criteria,\n",
    "        'generation_seed' : 42,\n",
    "    }\n",
    "\n",
    "    start = time.time()\n",
    "    scores, outputs = tuner_ob.get_score(gen_params1)\n",
    "    end = time.time()\n",
    "\n",
    "    score_at_diff_batch_sizes[batch_size] = {\n",
    "        'score' : scores,\n",
    "        'outputs' : outputs,\n",
    "        'optimal_batch_size' : tuner_ob.estimator._optimal_batch_size,\n",
    "        'latency_mins' : (end  - start) / 60,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size - 1\n",
      "Score - 0.64\n",
      "Latency - 2.4383922656377157 mins\n",
      "Optimal Batch Size - 1\n",
      "\n",
      "\n",
      "\n",
      "Batch Size - 2\n",
      "Score - 0.5\n",
      "Latency - 1.628644013404846 mins\n",
      "Optimal Batch Size - 2\n",
      "\n",
      "\n",
      "\n",
      "Batch Size - 4\n",
      "Score - 0.3\n",
      "Latency - 0.9731221199035645 mins\n",
      "Optimal Batch Size - 4\n",
      "\n",
      "\n",
      "\n",
      "Batch Size - 8\n",
      "Score - 0.16\n",
      "Latency - 0.49500605662663777 mins\n",
      "Optimal Batch Size - 8\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print out the results\n",
    "\n",
    "# proves that llmsearch should be run on a batch size of 1\n",
    "\n",
    "for batch_size, score_dict in score_at_diff_batch_sizes.items():\n",
    "    print(f\"Batch Size - {batch_size}\")\n",
    "    print(f\"Score - {score_dict['score']}\")\n",
    "    print(f\"Latency - {score_dict['latency_mins']} mins\")\n",
    "    print(f\"Optimal Batch Size - {score_dict['optimal_batch_size']}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_at_diff_batch_sizes[batch_size] = {\n",
    "        'score' : scores,\n",
    "        'outputs' : outputs,\n",
    "        'optimal_batch_size' : tuner_ob.estimator._optimal_batch_size,\n",
    "        'latency_mins' : (end  - start) / 60,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccdc7f50dee44318b32707644ad0bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f2a3e75d090>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(scores_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e646e754ca0e48a3b31172d1feee69b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llmsearch.tuner import Tuner\n",
    "\n",
    "cm()\n",
    "batch_size = 1\n",
    "\n",
    "tuner_ob = Tuner(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    dataset = bm_samples,\n",
    "    device = 'cuda:0',\n",
    "    batch_size = batch_size,\n",
    "    tokenizer_encoding_kwargs={'padding': 'longest', 'add_special_tokens' : False},\n",
    "    tokenizer_decoding_kwargs={'spaces_between_special_tokens' : False},\n",
    "    scorer = get_score,\n",
    "    prompt_template = langchain.PromptTemplate.from_template(\"{X}\"),\n",
    "    is_encoder_decoder = False,\n",
    "    seed = seed,\n",
    "    column_mapping = {'input_cols' : [\"X\"],'eval_cols' : ['answer']},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuner_ob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtuner_ob\u001b[49m\u001b[38;5;241m.\u001b[39m_optimal_batch_size\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tuner_ob' is not defined"
     ]
    }
   ],
   "source": [
    "tuner_ob._optimal_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccdc7f50dee44318b32707644ad0bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f2a3e75d090>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(scores_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 02:50:32.804 - llmsearch.utils.mem_utils:153 - INFO - Starting inference with generation parameters - {'max_new_tokens': 500, 'stopping_criteria': [<__main__.MultiTokenEOSCriteria object at 0x7f8a44537d00>], 'generation_seed': 42}\n",
      "2024-03-25 02:50:32.806 - llmsearch.utils.mem_utils:157 - INFO - Performing inference with batch_size - 2\n",
      "2024-03-25 02:50:32.808 - llmsearch.utils.model_utils:97 - INFO - Detected generation type - Greedy Decoding\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd81586f54a4a59a7fda363d8754609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "<|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Mimi picked up 2 dozen seashells on the beach.  Kyle found twice as many shells as Mimi and put them in his pocket. Leigh grabbed one-third of the shells that Kyle found.  How many seashells did Leigh have?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "A: Mimi picked up 2 dozen seashells, which is 2 * 12 = 24 seashells. Kyle found twice as many shells as Mimi, so he found 24 * 2 = 48 seashells. Leigh grabbed one-third of the shells that Kyle found, so Leigh had 48 / 3 = 16 seashells. The answer is 16.<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> \n",
      "\n",
      "<|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Mimi picked up 2 dozen seashells on the beach.  Kyle found twice as many shells as Mimi and put them in his pocket. Leigh grabbed one-third of the shells that Kyle found.  How many seashells did Leigh have?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Output :  A: Mimi picked up 2 dozen seashells, which is 2 * 12 = 24 seashells. Kyle found twice as many shells as Mimi, so he found 24 * 2 = 48 seashells. Leigh grabbed one-third of the shells that Kyle found, so Leigh had 48 / 3 = 16 seashells. The answer is 16.<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<|im_end|><|im_end|><|im_end|> <|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Frankie's parents let him have many pets. He has six more snakes than he has cats. He has one less parrot than cats. Six of his pets have four legs. He has 2 dogs. How many pets does he have in total?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "A: Let's use variables to represent the number of each type of pet:\n",
      "C = number of cats\n",
      "S = number of snakes\n",
      "P = number of parrots\n",
      "\n",
      "We are given the following information:\n",
      "1. S = C + 6 (Frankie has six more snakes than cats)\n",
      "2. P = C - 1 (Frankie has one less parrot than cats)\n",
      "3. 6 pets have 4 legs, and we know he has 2 dogs, so he has C + 4 pets with 4 legs.\n",
      "\n",
      "We are asked to find the total number of pets, which is C + S + P + 2.\n",
      "\n",
      "Now, we can use the given information to substitute and solve for the total number of pets:\n",
      "\n",
      "C + (C + 6) + (C - 1) + 2 = total number of pets\n",
      "3C + 5 = total number of pets\n",
      "\n",
      "Since we don't have the exact number of cats, we cannot find the exact total number of pets. However, we can express the total number of pets in terms of the number of cats: 3C + 5.<|im_end|> \n",
      "\n",
      "<|im_end|><|im_end|><|im_end|> <|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Frankie's parents let him have many pets. He has six more snakes than he has cats. He has one less parrot than cats. Six of his pets have four legs. He has 2 dogs. How many pets does he have in total?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Output :  A: Let's use variables to represent the number of each type of pet:\n",
      "C = number of cats\n",
      "S = number of snakes\n",
      "P = number of parrots\n",
      "\n",
      "We are given the following information:\n",
      "1. S = C + 6 (Frankie has six more snakes than cats)\n",
      "2. P = C - 1 (Frankie has one less parrot than cats)\n",
      "3. 6 pets have 4 legs, and we know he has 2 dogs, so he has C + 4 pets with 4 legs.\n",
      "\n",
      "We are asked to find the total number of pets, which is C + S + P + 2.\n",
      "\n",
      "Now, we can use the given information to substitute and solve for the total number of pets:\n",
      "\n",
      "C + (C + 6) + (C - 1) + 2 = total number of pets\n",
      "3C + 5 = total number of pets\n",
      "\n",
      "Since we don't have the exact number of cats, we cannot find the exact total number of pets. However, we can express the total number of pets in terms of the number of cats: 3C + 5.<|im_end|>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "here\n",
      "<|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Olaf collects colorful toy cars. At first, his collection consisted of 150 cars. His family, knowing his hobby, decided to give him some toy cars. Grandpa gave Olaf twice as many toy cars as the uncle. Dad gave Olaf 10 toy cars, 5 less than Mum. Auntie gave Olaf 6 toy cars, 1 more than the uncle. How many toy cars does Olaf have in total, after receiving all these gifts?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "A: Let's break down the information given:\n",
      "\n",
      "1. Olaf initially had 150 toy cars.\n",
      "2. Grandpa gave Olaf twice as many as Uncle, so Grandpa gave 2 * Uncle's cars.\n",
      "3. Dad gave Olaf 10 cars, 5 less than Mum, so Mum gave Olaf 10 + 5 = 15 cars.\n",
      "4. Auntie gave Olaf 6 cars, 1 more than Uncle, so Uncle gave Olaf 6 - 1 = 5 cars.\n",
      "\n",
      "Now let's calculate how many cars each family member gave:\n",
      "\n",
      "- Grandpa: 2 * Uncle's cars\n",
      "- Dad: 10 cars\n",
      "- Mum: 15 cars\n",
      "- Auntie: 6 cars\n",
      "\n",
      "Uncle's cars = 5 cars (as mentioned in the question)\n",
      "\n",
      "So, Grandpa gave 2 * 5 = 10 cars.\n",
      "\n",
      "Now let's add all the cars given by the family members:\n",
      "\n",
      "10 (Grandpa) + 10 (Dad) + 15 (Mum) + 6 (Auntie) = 41 cars\n",
      "\n",
      "Finally, let's add the initial 150 cars to the 41 cars given by the family members:\n",
      "\n",
      "150 (initial) + 41 (from family) = 191 cars\n",
      "\n",
      "The answer is 191.<|im_end|> \n",
      "\n",
      "<|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Olaf collects colorful toy cars. At first, his collection consisted of 150 cars. His family, knowing his hobby, decided to give him some toy cars. Grandpa gave Olaf twice as many toy cars as the uncle. Dad gave Olaf 10 toy cars, 5 less than Mum. Auntie gave Olaf 6 toy cars, 1 more than the uncle. How many toy cars does Olaf have in total, after receiving all these gifts?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Output :  A: Let's break down the information given:\n",
      "\n",
      "1. Olaf initially had 150 toy cars.\n",
      "2. Grandpa gave Olaf twice as many as Uncle, so Grandpa gave 2 * Uncle's cars.\n",
      "3. Dad gave Olaf 10 cars, 5 less than Mum, so Mum gave Olaf 10 + 5 = 15 cars.\n",
      "4. Auntie gave Olaf 6 cars, 1 more than Uncle, so Uncle gave Olaf 6 - 1 = 5 cars.\n",
      "\n",
      "Now let's calculate how many cars each family member gave:\n",
      "\n",
      "- Grandpa: 2 * Uncle's cars\n",
      "- Dad: 10 cars\n",
      "- Mum: 15 cars\n",
      "- Auntie: 6 cars\n",
      "\n",
      "Uncle's cars = 5 cars (as mentioned in the question)\n",
      "\n",
      "So, Grandpa gave 2 * 5 = 10 cars.\n",
      "\n",
      "Now let's add all the cars given by the family members:\n",
      "\n",
      "10 (Grandpa) + 10 (Dad) + 15 (Mum) + 6 (Auntie) = 41 cars\n",
      "\n",
      "Finally, let's add the initial 150 cars to the 41 cars given by the family members:\n",
      "\n",
      "150 (initial) + 41 (from family) = 191 cars\n",
      "\n",
      "The answer is 191.<|im_end|>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|> <|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Emma's bank account has $100 in it. Each day of the week, she spends $8. At the end of the week, she goes to the bank and asks for as many $5 bills as her account can give her. She leaves the rest in the account. How many dollars remain in the account?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> \n",
      "\n",
      "<|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|> <|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Emma's bank account has $100 in it. Each day of the week, she spends $8. At the end of the week, she goes to the bank and asks for as many $5 bills as her account can give her. She leaves the rest in the account. How many dollars remain in the account?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Output :  Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "here\n",
      "<|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|> <|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Ezekiel hikes as a hobby. This past summer, he did a challenging three-day hike across 50 kilometers of wilderness. The first day, he covered 10 kilometers of steep mountainside. The second day was flatter and he was able to cover half the full hike distance. How many kilometers did he have to hike on the third day to finish the hike?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "He had to hike 20 kilometers on the third day to finish the hike.<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> \n",
      "\n",
      "<|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|> <|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Ezekiel hikes as a hobby. This past summer, he did a challenging three-day hike across 50 kilometers of wilderness. The first day, he covered 10 kilometers of steep mountainside. The second day was flatter and he was able to cover half the full hike distance. How many kilometers did he have to hike on the third day to finish the hike?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Output :  He had to hike 20 kilometers on the third day to finish the hike.<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: James decides to build a tin house by collecting 500 tins in a week. On the first day, he collects 50 tins. On the second day, he manages to collect 3 times that number. On the third day, he collects 50 tins fewer than the number he collected on the second day. If he collects an equal number of tins on the remaining days of the week, what's the number of tins he collected each day for the rest of the week?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "A: On the first day, James collects 50 tins. On the second day, he collects 3 times that number, which is 3 * 50 = 150 tins. On the third day, he collects 50 tins fewer than the second day, which is 150 - 50 = 100 tins.\n",
      "\n",
      "So far, he has collected 50 + 150 + 100 = 300 tins in the first three days.\n",
      "\n",
      "He wants to collect 500 tins in total, so he needs to collect 500 - 300 = 200 tins in the remaining days of the week.\n",
      "\n",
      "Since he collects an equal number of tins each day for the rest of the week, he collects 200 tins / 5 days = 40 tins per day. The answer is 40.<|im_end|> \n",
      "\n",
      "<|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: James decides to build a tin house by collecting 500 tins in a week. On the first day, he collects 50 tins. On the second day, he manages to collect 3 times that number. On the third day, he collects 50 tins fewer than the number he collected on the second day. If he collects an equal number of tins on the remaining days of the week, what's the number of tins he collected each day for the rest of the week?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Output :  A: On the first day, James collects 50 tins. On the second day, he collects 3 times that number, which is 3 * 50 = 150 tins. On the third day, he collects 50 tins fewer than the second day, which is 150 - 50 = 100 tins.\n",
      "\n",
      "So far, he has collected 50 + 150 + 100 = 300 tins in the first three days.\n",
      "\n",
      "He wants to collect 500 tins in total, so he needs to collect 500 - 300 = 200 tins in the remaining days of the week.\n",
      "\n",
      "Since he collects an equal number of tins each day for the rest of the week, he collects 200 tins / 5 days = 40 tins per day. The answer is 40.<|im_end|>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "here\n",
      "<|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|> <|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Don throws 3 darts.  One is a bullseye worth 50 points.  One completely missed the target, so received no points. The third was worth half the points of the bullseye.  What is the final score from these 3 throws?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "Q:<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> \n",
      "\n",
      "<|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|> <|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Don throws 3 darts.  One is a bullseye worth 50 points.  One completely missed the target, so received no points. The third was worth half the points of the bullseye.  What is the final score from these 3 throws?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Output :  Q:<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: TreQuan is throwing rocks in the river and he notices that the bigger the rock, the wider the splash. Pebbles make a splash that is a 1/4 meter wide. Rocks make a splash that is 1/2 a meter wide, and boulders create a splash that is 2 meters wide. If he tosses 6 pebbles, 3 rocks, and 2 boulders, what is the total width of the splashes he makes?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "A: First, we need to find the total width of the splashes made by each type of rock.\n",
      "\n",
      "For pebbles, there are 6 pebbles and each pebble makes a splash 1/4 meter wide. So, the total width of the pebble splashes is 6 * (1/4) = 6/4 = 1.5 meters.\n",
      "\n",
      "For rocks, there are 3 rocks and each rock makes a splash 1/2 meter wide. So, the total width of the rock splashes is 3 * (1/2) = 3/2 = 1.5 meters.\n",
      "\n",
      "For boulders, there are 2 boulders and each boulder makes a splash 2 meters wide. So, the total width of the boulder splashes is 2 * 2 = 4 meters.\n",
      "\n",
      "Now, we add up the total width of all the splashes: 1.5 (pebbles) + 1.5 (rocks) + 4 (boulders) = 1.5 + 1.5 + 4 = 7 meters.\n",
      "\n",
      "The answer is 7.<|im_end|> \n",
      "\n",
      "<|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: TreQuan is throwing rocks in the river and he notices that the bigger the rock, the wider the splash. Pebbles make a splash that is a 1/4 meter wide. Rocks make a splash that is 1/2 a meter wide, and boulders create a splash that is 2 meters wide. If he tosses 6 pebbles, 3 rocks, and 2 boulders, what is the total width of the splashes he makes?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Output :  A: First, we need to find the total width of the splashes made by each type of rock.\n",
      "\n",
      "For pebbles, there are 6 pebbles and each pebble makes a splash 1/4 meter wide. So, the total width of the pebble splashes is 6 * (1/4) = 6/4 = 1.5 meters.\n",
      "\n",
      "For rocks, there are 3 rocks and each rock makes a splash 1/2 meter wide. So, the total width of the rock splashes is 3 * (1/2) = 3/2 = 1.5 meters.\n",
      "\n",
      "For boulders, there are 2 boulders and each boulder makes a splash 2 meters wide. So, the total width of the boulder splashes is 2 * 2 = 4 meters.\n",
      "\n",
      "Now, we add up the total width of all the splashes: 1.5 (pebbles) + 1.5 (rocks) + 4 (boulders) = 1.5 + 1.5 + 4 = 7 meters.\n",
      "\n",
      "The answer is 7.<|im_end|>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "here\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 02:50:53.971 - llmsearch.utils.model_utils:135 - DEBUG - Input - '<|im_start|>system\\nSolve the following math problems, end with The answer is<|im_end|>\\n<|im_start|>user\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\n\\nQ: Mimi picked up 2 dozen seashells on the beach.  Kyle found twice as many shells as Mimi and put them in his pocket. Leigh grabbed one-third of the shells that Kyle found.  How many seashells did Leigh have?<|im_end|>\\n<|im_start|>assistant\\n'\n",
      "2024-03-25 02:50:53.973 - llmsearch.utils.model_utils:136 - DEBUG - Model Output - 'A: Mimi picked up 2 dozen seashells, which is 2 * 12 = 24 seashells. Kyle found twice as many shells as Mimi, so he found 24 * 2 = 48 seashells. Leigh grabbed one-third of the shells that Kyle found, so Leigh had 48 / 3 = 16 seashells. The answer is 16.<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>'\n",
      "2024-03-25 02:50:53.975 - llmsearch.utils.model_utils:135 - DEBUG - Input - \"<|im_start|>system\\nSolve the following math problems, end with The answer is<|im_end|>\\n<|im_start|>user\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\n\\nQ: Frankie's parents let him have many pets. He has six more snakes than he has cats. He has one less parrot than cats. Six of his pets have four legs. He has 2 dogs. How many pets does he have in total?<|im_end|>\\n<|im_start|>assistant\\n\"\n",
      "2024-03-25 02:50:53.976 - llmsearch.utils.model_utils:136 - DEBUG - Model Output - \"A: Let's use variables to represent the number of each type of pet:\\nC = number of cats\\nS = number of snakes\\nP = number of parrots\\n\\nWe are given the following information:\\n1. S = C + 6 (Frankie has six more snakes than cats)\\n2. P = C - 1 (Frankie has one less parrot than cats)\\n3. 6 pets have 4 legs, and we know he has 2 dogs, so he has C + 4 pets with 4 legs.\\n\\nWe are asked to find the total number of pets, which is C + S + P + 2.\\n\\nNow, we can use the given information to substitute and solve for the total number of pets:\\n\\nC + (C + 6) + (C - 1) + 2 = total number of pets\\n3C + 5 = total number of pets\\n\\nSince we don't have the exact number of cats, we cannot find the exact total number of pets. However, we can express the total number of pets in terms of the number of cats: 3C + 5.<|im_end|>\"\n",
      "2024-03-25 02:50:53.977 - llmsearch.utils.model_utils:135 - DEBUG - Input - '<|im_start|>system\\nSolve the following math problems, end with The answer is<|im_end|>\\n<|im_start|>user\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\n\\nQ: Olaf collects colorful toy cars. At first, his collection consisted of 150 cars. His family, knowing his hobby, decided to give him some toy cars. Grandpa gave Olaf twice as many toy cars as the uncle. Dad gave Olaf 10 toy cars, 5 less than Mum. Auntie gave Olaf 6 toy cars, 1 more than the uncle. How many toy cars does Olaf have in total, after receiving all these gifts?<|im_end|>\\n<|im_start|>assistant\\n'\n",
      "2024-03-25 02:50:53.979 - llmsearch.utils.model_utils:136 - DEBUG - Model Output - \"A: Let's break down the information given:\\n\\n1. Olaf initially had 150 toy cars.\\n2. Grandpa gave Olaf twice as many as Uncle, so Grandpa gave 2 * Uncle's cars.\\n3. Dad gave Olaf 10 cars, 5 less than Mum, so Mum gave Olaf 10 + 5 = 15 cars.\\n4. Auntie gave Olaf 6 cars, 1 more than Uncle, so Uncle gave Olaf 6 - 1 = 5 cars.\\n\\nNow let's calculate how many cars each family member gave:\\n\\n- Grandpa: 2 * Uncle's cars\\n- Dad: 10 cars\\n- Mum: 15 cars\\n- Auntie: 6 cars\\n\\nUncle's cars = 5 cars (as mentioned in the question)\\n\\nSo, Grandpa gave 2 * 5 = 10 cars.\\n\\nNow let's add all the cars given by the family members:\\n\\n10 (Grandpa) + 10 (Dad) + 15 (Mum) + 6 (Auntie) = 41 cars\\n\\nFinally, let's add the initial 150 cars to the 41 cars given by the family members:\\n\\n150 (initial) + 41 (from family) = 191 cars\\n\\nThe answer is 191.<|im_end|>\"\n",
      "2024-03-25 02:50:53.980 - llmsearch.utils.model_utils:135 - DEBUG - Input - \"<|im_start|>system\\nSolve the following math problems, end with The answer is<|im_end|>\\n<|im_start|>user\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\n\\nQ: Emma's bank account has $100 in it. Each day of the week, she spends $8. At the end of the week, she goes to the bank and asks for as many $5 bills as her account can give her. She leaves the rest in the account. How many dollars remain in the account?<|im_end|>\\n<|im_start|>assistant\\n\"\n",
      "2024-03-25 02:50:53.982 - llmsearch.utils.model_utils:136 - DEBUG - Model Output - 'Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>'\n",
      "2024-03-25 02:50:53.982 - llmsearch.utils.model_utils:135 - DEBUG - Input - '<|im_start|>system\\nSolve the following math problems, end with The answer is<|im_end|>\\n<|im_start|>user\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\n\\nQ: Ezekiel hikes as a hobby. This past summer, he did a challenging three-day hike across 50 kilometers of wilderness. The first day, he covered 10 kilometers of steep mountainside. The second day was flatter and he was able to cover half the full hike distance. How many kilometers did he have to hike on the third day to finish the hike?<|im_end|>\\n<|im_start|>assistant\\n'\n",
      "2024-03-25 02:50:53.983 - llmsearch.utils.model_utils:136 - DEBUG - Model Output - 'He had to hike 20 kilometers on the third day to finish the hike.<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>'\n",
      "2024-03-25 02:50:53.984 - llmsearch.utils.model_utils:135 - DEBUG - Input - \"<|im_start|>system\\nSolve the following math problems, end with The answer is<|im_end|>\\n<|im_start|>user\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\n\\nQ: James decides to build a tin house by collecting 500 tins in a week. On the first day, he collects 50 tins. On the second day, he manages to collect 3 times that number. On the third day, he collects 50 tins fewer than the number he collected on the second day. If he collects an equal number of tins on the remaining days of the week, what's the number of tins he collected each day for the rest of the week?<|im_end|>\\n<|im_start|>assistant\\n\"\n",
      "2024-03-25 02:50:53.984 - llmsearch.utils.model_utils:136 - DEBUG - Model Output - 'A: On the first day, James collects 50 tins. On the second day, he collects 3 times that number, which is 3 * 50 = 150 tins. On the third day, he collects 50 tins fewer than the second day, which is 150 - 50 = 100 tins.\\n\\nSo far, he has collected 50 + 150 + 100 = 300 tins in the first three days.\\n\\nHe wants to collect 500 tins in total, so he needs to collect 500 - 300 = 200 tins in the remaining days of the week.\\n\\nSince he collects an equal number of tins each day for the rest of the week, he collects 200 tins / 5 days = 40 tins per day. The answer is 40.<|im_end|>'\n",
      "2024-03-25 02:50:53.985 - llmsearch.utils.model_utils:135 - DEBUG - Input - '<|im_start|>system\\nSolve the following math problems, end with The answer is<|im_end|>\\n<|im_start|>user\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\n\\nQ: Don throws 3 darts.  One is a bullseye worth 50 points.  One completely missed the target, so received no points. The third was worth half the points of the bullseye.  What is the final score from these 3 throws?<|im_end|>\\n<|im_start|>assistant\\n'\n",
      "2024-03-25 02:50:53.985 - llmsearch.utils.model_utils:136 - DEBUG - Model Output - 'Q:<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>'\n",
      "2024-03-25 02:50:53.986 - llmsearch.utils.model_utils:135 - DEBUG - Input - '<|im_start|>system\\nSolve the following math problems, end with The answer is<|im_end|>\\n<|im_start|>user\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\n\\nQ: TreQuan is throwing rocks in the river and he notices that the bigger the rock, the wider the splash. Pebbles make a splash that is a 1/4 meter wide. Rocks make a splash that is 1/2 a meter wide, and boulders create a splash that is 2 meters wide. If he tosses 6 pebbles, 3 rocks, and 2 boulders, what is the total width of the splashes he makes?<|im_end|>\\n<|im_start|>assistant\\n'\n",
      "2024-03-25 02:50:53.987 - llmsearch.utils.model_utils:136 - DEBUG - Model Output - 'A: First, we need to find the total width of the splashes made by each type of rock.\\n\\nFor pebbles, there are 6 pebbles and each pebble makes a splash 1/4 meter wide. So, the total width of the pebble splashes is 6 * (1/4) = 6/4 = 1.5 meters.\\n\\nFor rocks, there are 3 rocks and each rock makes a splash 1/2 meter wide. So, the total width of the rock splashes is 3 * (1/2) = 3/2 = 1.5 meters.\\n\\nFor boulders, there are 2 boulders and each boulder makes a splash 2 meters wide. So, the total width of the boulder splashes is 2 * 2 = 4 meters.\\n\\nNow, we add up the total width of all the splashes: 1.5 (pebbles) + 1.5 (rocks) + 4 (boulders) = 1.5 + 1.5 + 4 = 7 meters.\\n\\nThe answer is 7.<|im_end|>'\n",
      "2024-03-25 02:50:53.987 - llmsearch.utils.model_utils:135 - DEBUG - Input - '<|im_start|>system\\nSolve the following math problems, end with The answer is<|im_end|>\\n<|im_start|>user\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\n\\nQ: Pauly is making omelets for his family. There are three dozen eggs, and he plans to use them all. Each omelet requires 4 eggs. Including himself, there are 3 people. How many omelets does each person get?<|im_end|>\\n<|im_start|>assistant\\n'\n",
      "2024-03-25 02:50:53.988 - llmsearch.utils.model_utils:136 - DEBUG - Model Output - '3 dozen eggs.\\n\\nThe answer is 3 dozen eggs.\\n\\nQ: Pauly is making omelets for his family. There are three dozen eggs, and he plans to use them all. Each omelet requires 4 eggs. Including himself, there are 3 people. How many omelets does each person get?<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>'\n",
      "2024-03-25 02:50:53.988 - llmsearch.utils.model_utils:135 - DEBUG - Input - '<|im_start|>system\\nSolve the following math problems, end with The answer is<|im_end|>\\n<|im_start|>user\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\n\\nQ: Thomas made 4 stacks of wooden blocks. The first stack was 7 blocks tall. The second stack was 3 blocks taller than the first. The third stack was 6 blocks shorter than the second stack, and the fourth stack was 10 blocks taller than the third stack. If the fifth stack has twice as many blocks as the second stack, how many blocks did Thomas use in all?<|im_end|>\\n<|im_start|>assistant\\n'\n",
      "2024-03-25 02:50:53.989 - llmsearch.utils.model_utils:136 - DEBUG - Model Output - 'A: The first stack has 7 blocks. The second stack is 3 blocks taller, so it has 7 + 3 = 10 blocks. The third stack is 6 blocks shorter, so it has 10 - 6 = 4 blocks. The fourth stack is 10 blocks taller, so it has 4 + 10 = 14 blocks. The fifth stack has twice as many blocks as the second stack, so it has 10 * 2 = 20 blocks. In total, Thomas used 7 + 10 + 4 + 14 + 20 = 55 blocks. The answer is 55.<|im_end|>'\n",
      "2024-03-25 02:50:54.143 - llmsearch.utils.mem_utils:175 - DEBUG - Setting batch_size cache value - 2 for this particular configuration\n",
      "2024-03-25 02:50:54.143 - llmsearch.utils.mem_utils:187 - INFO - Finished running inference, took 21.335601 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|> <|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Pauly is making omelets for his family. There are three dozen eggs, and he plans to use them all. Each omelet requires 4 eggs. Including himself, there are 3 people. How many omelets does each person get?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "3 dozen eggs.\n",
      "\n",
      "The answer is 3 dozen eggs.\n",
      "\n",
      "Q: Pauly is making omelets for his family. There are three dozen eggs, and he plans to use them all. Each omelet requires 4 eggs. Including himself, there are 3 people. How many omelets does each person get?<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk> \n",
      "\n",
      "<|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|><|im_end|> <|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Pauly is making omelets for his family. There are three dozen eggs, and he plans to use them all. Each omelet requires 4 eggs. Including himself, there are 3 people. How many omelets does each person get?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Output :  3 dozen eggs.\n",
      "\n",
      "The answer is 3 dozen eggs.\n",
      "\n",
      "Q: Pauly is making omelets for his family. There are three dozen eggs, and he plans to use them all. Each omelet requires 4 eggs. Including himself, there are 3 people. How many omelets does each person get?<|im_end|><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Thomas made 4 stacks of wooden blocks. The first stack was 7 blocks tall. The second stack was 3 blocks taller than the first. The third stack was 6 blocks shorter than the second stack, and the fourth stack was 10 blocks taller than the third stack. If the fifth stack has twice as many blocks as the second stack, how many blocks did Thomas use in all?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "A: The first stack has 7 blocks. The second stack is 3 blocks taller, so it has 7 + 3 = 10 blocks. The third stack is 6 blocks shorter, so it has 10 - 6 = 4 blocks. The fourth stack is 10 blocks taller, so it has 4 + 10 = 14 blocks. The fifth stack has twice as many blocks as the second stack, so it has 10 * 2 = 20 blocks. In total, Thomas used 7 + 10 + 4 + 14 + 20 = 55 blocks. The answer is 55.<|im_end|> \n",
      "\n",
      "<|im_start|>system\n",
      "Solve the following math problems, end with The answer is<|im_end|>\n",
      "<|im_start|>user\n",
      "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n",
      "A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n",
      "\n",
      "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
      "A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n",
      "\n",
      "Q: Thomas made 4 stacks of wooden blocks. The first stack was 7 blocks tall. The second stack was 3 blocks taller than the first. The third stack was 6 blocks shorter than the second stack, and the fourth stack was 10 blocks taller than the third stack. If the fifth stack has twice as many blocks as the second stack, how many blocks did Thomas use in all?<|im_end|>\n",
      "<|im_start|>assistant\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Output :  A: The first stack has 7 blocks. The second stack is 3 blocks taller, so it has 7 + 3 = 10 blocks. The third stack is 6 blocks shorter, so it has 10 - 6 = 4 blocks. The fourth stack is 10 blocks taller, so it has 4 + 10 = 14 blocks. The fifth stack has twice as many blocks as the second stack, so it has 10 * 2 = 20 blocks. In total, Thomas used 7 + 10 + 4 + 14 + 20 = 55 blocks. The answer is 55.<|im_end|>\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decoder parser is working as expected\n",
    "# TODO : check scores at different bs then llmsearch\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([MultiTokenEOSCriteria(sequence_ids = [32000])])\n",
    "\n",
    "gen_params1 = {\n",
    "    'max_new_tokens' : 500,\n",
    "    'stopping_criteria' : stopping_criteria,\n",
    "    'generation_seed' : 42,\n",
    "}\n",
    "\n",
    "scores_before, outputs_before = tuner_ob.get_score(gen_params1)\n",
    "\n",
    "scores_before"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
