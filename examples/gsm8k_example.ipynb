{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/root/miniconda3/envs/llmsearch-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"name":"stdout","output_type":"stream","text":["Monkey Patching .generate function of `transformers` library\n","0.2.4 2.2.0+cu121 4.38.2 0.1.0\n"]}],"source":["# uses autoawq==0.2.4 autoawq_kernels==0.0.6\n","\"\"\"\n","model - 7B model - https://huggingface.co/TheBloke/CapybaraHermes-2.5-Mistral-7B-AWQ\n","dataset - gsm8k train split, llmsearch is run on a subset and evaluated on another\n","\n","\n","Requires:\n","autoawq==0.2.4 & autoawq_kernels==0.0.6\n","\"\"\"\n","\n","import awq\n","import torch\n","import transformers\n","\n","import llmsearch\n","\n","print(awq.__version__, torch.__version__, transformers.__version__, llmsearch.__version__)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import re\n","import textwrap\n","from pathlib import Path\n","\n","import datasets\n","\n","from awq import AutoAWQForCausalLM\n","from sklearn.model_selection import GridSearchCV\n","from transformers import StoppingCriteriaList, AutoTokenizer\n","\n","from llmsearch.tuner import Tuner\n","from llmsearch.utils.mem_utils import gc_cuda\n","from llmsearch.utils.common_utils import json_load, json_dump\n","from llmsearch.utils.model_downloader import download_model_from_hf\n","from llmsearch.scripts.stopping_criteria import MultiTokenStoppingCriteria"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["seed = 42\n","batch_size = 1\n","num_tune_samples = 150\n","num_test_samples = 500\n","model_id = \"TheBloke/CapybaraHermes-2.5-Mistral-7B-AWQ\"\n","device = \"cuda:0\""]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def load_model_and_tokenizer(model_id, temp_model_dir):\n","    temp_model_dir.mkdir(exist_ok=True, parents=True)\n","    output_folder = download_model_from_hf(model_id, save_dir=temp_model_dir, branch=\"main\")\n","\n","    gc_cuda()\n","\n","    model = AutoAWQForCausalLM.from_quantized(\n","        quant_path=output_folder, fuse_layers=True, device_map={\"\": device}, local_files_only=True\n","    )\n","\n","    tokenizer = AutoTokenizer.from_pretrained(\n","        output_folder, local_files_only=True, legacy=False, use_fast=False\n","    )\n","    tokenizer.pad_token = tokenizer.unk_token\n","    tokenizer.padding_side = \"left\"\n","\n","    return model, tokenizer\n","\n","def load_dataset():\n","\n","    def preprocess_dataset(\n","        dataset, tokenizer, pt, pt_cols, system_prompt, add_generation_prompt=True\n","    ):\n","\n","        def wrapper(sample):\n","            \"\"\"Takes in a sample, formats it using prompt template, applies chat template and returns the formatted string\"\"\"\n","            messages = (\n","                []\n","                if system_prompt is None\n","                else [{\"role\": \"system\", \"content\": system_prompt}]\n","            )\n","            formatted_pt = pt.format(**{pt_col: sample[pt_col] for pt_col in pt_cols})\n","            messages.append(\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": formatted_pt,\n","                }\n","            )\n","            formatted_pt_with_ct = tokenizer.apply_chat_template(\n","                messages, tokenize=False, add_generation_prompt=add_generation_prompt\n","            )\n","            return formatted_pt_with_ct\n","\n","        def actual_input(sample):\n","            \"\"\"Takes in a sample, formats it using prompt template, applies chat template and returns the formatted string\"\"\"\n","            return sample[pt_cols[0]]\n","\n","        pt_dataset = dataset.map(\n","            lambda sample: {\n","                \"X\": wrapper(sample),\n","                \"actual input\": actual_input(sample),\n","            }\n","        )\n","\n","        return pt_dataset\n","\n","\n","    # 2-shot prompt template - https://github.com/EleutherAI/lm-evaluation-harness/blob/main/lm_eval/tasks/gsm8k/gsm8k-cot.yaml\n","    pt = textwrap.dedent(\n","    \"\"\"\\\n","    Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\n","    A: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\n","\n","    Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n","    A: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\n","\n","    Q: {question}\"\"\"\n","    )\n","    pt_cols = [\"question\"]\n","    system_prompt = \"Solve the following math problems, end with The answer is\"\n","    gsm8k_dataset = datasets.load_dataset(\"gsm8k\", \"main\")\n","\n","\n","    processed_dataset = preprocess_dataset(\n","        gsm8k_dataset[\"train\"],\n","        tokenizer,\n","        pt=pt,\n","        pt_cols=pt_cols,\n","        system_prompt=system_prompt,\n","        add_generation_prompt=True,\n","    )\n","\n","    shuffled_dataset = processed_dataset.shuffle(seed=seed)\n","\n","    samples_to_tune_on = shuffled_dataset.select(range(num_tune_samples))\n","    remaining_indices = range(num_tune_samples, num_tune_samples + num_test_samples)\n","    test_dataset = shuffled_dataset.select(remaining_indices)\n","    return samples_to_tune_on, test_dataset\n","\n","def get_score(y_true, y_pred):\n","    def standardize(s):\n","        if s is None:\n","            return s\n","        s = s.replace(\",\", \"\")\n","        if s.endswith(\".\"):\n","            s = s[:-1]\n","        return s.strip()\n","\n","    def extract_answer_from_out(s):\n","        pattern = re.compile(r\"The answer is ((\\d|\\-)((\\d|\\,|\\.)+)?\\d?)\")\n","        match = pattern.search(s)\n","        if match:\n","            return match.group(1).strip()\n","        else:\n","            return None\n","\n","    scores = []\n","\n","    for y_t, y_p in zip(y_true, y_pred):\n","        y_t_answer = y_t[\"answer\"].split(\"####\")[-1].strip()\n","        y_p_answer = extract_answer_from_out(y_p)\n","\n","        y_t_answer = standardize(y_t_answer)\n","        y_p_answer = standardize(y_p_answer)\n","\n","        # print(\"y_pred - \", y_p_answer)\n","        # print(\"y_true - \", y_t_answer)\n","\n","        if y_t_answer == y_p_answer:\n","            scores.append(1)\n","        else:\n","            scores.append(0)\n","    return sum(scores) / len(scores)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model already exists in temp_dir/TheBloke_CapybaraHermes-2.5-Mistral-7B-AWQ. Checking the model files...\n","Checksum validated: model.safetensors  645dfc7f09074aaf25e642f3c6a4f7ea399a0ff2605fa650e4e74078832546de\n","Checksum validated: tokenizer.model  dadfd56d766715c61d2ef780a525ab43b8e6da4de6865bda3d95fdef5e134055\n","[+] Validated checksums of all model files!\n"]},{"name":"stderr","output_type":"stream","text":["Replacing layers...: 100%|██████████| 32/32 [00:03<00:00,  9.06it/s]\n","Fusing layers...: 100%|██████████| 32/32 [00:03<00:00,  9.62it/s]\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Map: 100%|██████████| 7473/7473 [00:00<00:00, 11001.58 examples/s]\n"]}],"source":["# Load Model, Tokenizer, Dataset\n","temp_model_dir = Path(f\"./temp_dir/\")\n","temp_model_dir.mkdir(exist_ok=True, parents=True)\n","\n","model, tokenizer = load_model_and_tokenizer(model_id, temp_model_dir)\n","\n","# Dataset we will use to find the best generation parameters\n","samples_to_tune_on,test_dataset = load_dataset()\n","\n","multi_token_stop_criteria_ob = MultiTokenStoppingCriteria(sequence_ids=[32000])\n","stopping_criteria = StoppingCriteriaList([multi_token_stop_criteria_ob])\n","callbacks_after_inference = [multi_token_stop_criteria_ob.reset]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["tuner_ob = Tuner(\n","    model=model,\n","    tokenizer=tokenizer,\n","    dataset=samples_to_tune_on,\n","    device=\"cuda:0\",\n","    batch_size=batch_size,\n","    tokenizer_encode_args={\"padding\": \"longest\", \"add_special_tokens\": False},\n","    tokenizer_decode_args={\"spaces_between_special_tokens\": False, 'skip_special_tokens' : True},\n","    scorer=get_score,\n","    prompt_template=\"{X}\",\n","    seed=seed,\n","    column_mapping={\"input_cols\": [\"X\"], \"eval_cols\": [\"answer\"]},\n","    callbacks_after_inference=callbacks_after_inference,\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 150/150 [05:59<00:00,  2.39s/it]\n"]}],"source":["gen_params1 = {\n","    \"max_new_tokens\": 500,\n","    \"stopping_criteria\": stopping_criteria,\n","    \"generation_seed\": 42,\n","}\n","\n","scores_before, outputs_before = tuner_ob.get_score(gen_params1)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["hyp_space = {\n","    'max_new_tokens' : [500],\n","    'stopping_criteria' : [stopping_criteria],\n","    'generation_seed' : [42],\n","    'do_sample' : [True],\n","\n","    'top_k': [10,50,60,70,80],\n","    'top_p' : [0.7,0.75,0.8,0.95],\n","    'no_repeat_ngram_size': [0],\n","\n","}\n","\n","clf = GridSearchCV(\n","    estimator = tuner_ob.estimator,\n","    param_grid=hyp_space,\n","    scoring = tuner_ob.scorer,\n","    cv = 2,\n","    n_jobs = None,\n","    verbose=3,\n",")\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/75 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:12<00:00,  2.56s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=10, top_p=0.7;, score=0.707 total time= 3.2min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:51<00:00,  2.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=10, top_p=0.7;, score=0.693 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:09<00:00,  2.52s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=10, top_p=0.75;, score=0.667 total time= 3.2min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:50<00:00,  2.27s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=10, top_p=0.75;, score=0.747 total time= 2.8min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:03<00:00,  2.45s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=10, top_p=0.8;, score=0.733 total time= 3.1min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:51<00:00,  2.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=10, top_p=0.8;, score=0.707 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:10<00:00,  2.54s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=10, top_p=0.95;, score=0.747 total time= 3.2min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:54<00:00,  2.32s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=10, top_p=0.95;, score=0.680 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:08<00:00,  2.51s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=50, top_p=0.7;, score=0.720 total time= 3.1min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:52<00:00,  2.30s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=50, top_p=0.7;, score=0.693 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:09<00:00,  2.53s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=50, top_p=0.75;, score=0.640 total time= 3.2min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:54<00:00,  2.33s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=50, top_p=0.75;, score=0.720 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:06<00:00,  2.48s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=50, top_p=0.8;, score=0.680 total time= 3.1min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:47<00:00,  2.23s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=50, top_p=0.8;, score=0.733 total time= 2.8min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:10<00:00,  2.54s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=50, top_p=0.95;, score=0.720 total time= 3.2min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:51<00:00,  2.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=50, top_p=0.95;, score=0.653 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:08<00:00,  2.51s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=60, top_p=0.7;, score=0.720 total time= 3.1min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:51<00:00,  2.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=60, top_p=0.7;, score=0.693 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:08<00:00,  2.52s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=60, top_p=0.75;, score=0.640 total time= 3.2min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:54<00:00,  2.32s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=60, top_p=0.75;, score=0.720 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:05<00:00,  2.48s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=60, top_p=0.8;, score=0.680 total time= 3.1min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:46<00:00,  2.22s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=60, top_p=0.8;, score=0.733 total time= 2.8min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:10<00:00,  2.54s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=60, top_p=0.95;, score=0.720 total time= 3.2min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:51<00:00,  2.28s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=60, top_p=0.95;, score=0.653 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:08<00:00,  2.51s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=70, top_p=0.7;, score=0.720 total time= 3.1min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:51<00:00,  2.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=70, top_p=0.7;, score=0.693 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:08<00:00,  2.52s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=70, top_p=0.75;, score=0.640 total time= 3.1min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:53<00:00,  2.32s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=70, top_p=0.75;, score=0.720 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:05<00:00,  2.47s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=70, top_p=0.8;, score=0.680 total time= 3.1min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:45<00:00,  2.21s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=70, top_p=0.8;, score=0.733 total time= 2.8min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:10<00:00,  2.54s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=70, top_p=0.95;, score=0.720 total time= 3.2min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:51<00:00,  2.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=70, top_p=0.95;, score=0.653 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:08<00:00,  2.51s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=80, top_p=0.7;, score=0.720 total time= 3.1min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:53<00:00,  2.31s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=80, top_p=0.7;, score=0.693 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:09<00:00,  2.52s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=80, top_p=0.75;, score=0.640 total time= 3.2min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:53<00:00,  2.32s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=80, top_p=0.75;, score=0.720 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:05<00:00,  2.48s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=80, top_p=0.8;, score=0.680 total time= 3.1min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:46<00:00,  2.22s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=80, top_p=0.8;, score=0.733 total time= 2.8min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [03:09<00:00,  2.53s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[CV 1/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=80, top_p=0.95;, score=0.720 total time= 3.2min\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 75/75 [02:52<00:00,  2.30s/it]"]},{"name":"stdout","output_type":"stream","text":["[CV 2/2] END do_sample=True, generation_seed=42, max_new_tokens=500, no_repeat_ngram_size=0, stopping_criteria=[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], top_k=80, top_p=0.95;, score=0.653 total time= 2.9min\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n","             estimator=LLMEstimatorWrapper(batch_size=1,\n","                                           callbacks_after_inference=[&lt;bound method MultiTokenStoppingCriteria.reset of &lt;llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40&gt;&gt;],\n","                                           device=&#x27;cuda:0&#x27;, do_sample=True,\n","                                           generation_seed=42, is_fitted_=True,\n","                                           max_new_tokens=500,\n","                                           model=MistralAWQForCausalLM(\n","  (model): Mistra...\n","                                                                  &#x27;padding&#x27;: &#x27;longest&#x27;},\n","                                           top_k=10, top_p=0.8),\n","             param_grid={&#x27;do_sample&#x27;: [True], &#x27;generation_seed&#x27;: [42],\n","                         &#x27;max_new_tokens&#x27;: [500], &#x27;no_repeat_ngram_size&#x27;: [0],\n","                         &#x27;stopping_criteria&#x27;: [[&lt;llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40&gt;]],\n","                         &#x27;top_k&#x27;: [10, 50, 60, 70, 80],\n","                         &#x27;top_p&#x27;: [0.7, 0.75, 0.8, 0.95]},\n","             scoring=make_scorer(get_score), verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n","             estimator=LLMEstimatorWrapper(batch_size=1,\n","                                           callbacks_after_inference=[&lt;bound method MultiTokenStoppingCriteria.reset of &lt;llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40&gt;&gt;],\n","                                           device=&#x27;cuda:0&#x27;, do_sample=True,\n","                                           generation_seed=42, is_fitted_=True,\n","                                           max_new_tokens=500,\n","                                           model=MistralAWQForCausalLM(\n","  (model): Mistra...\n","                                                                  &#x27;padding&#x27;: &#x27;longest&#x27;},\n","                                           top_k=10, top_p=0.8),\n","             param_grid={&#x27;do_sample&#x27;: [True], &#x27;generation_seed&#x27;: [42],\n","                         &#x27;max_new_tokens&#x27;: [500], &#x27;no_repeat_ngram_size&#x27;: [0],\n","                         &#x27;stopping_criteria&#x27;: [[&lt;llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40&gt;]],\n","                         &#x27;top_k&#x27;: [10, 50, 60, 70, 80],\n","                         &#x27;top_p&#x27;: [0.7, 0.75, 0.8, 0.95]},\n","             scoring=make_scorer(get_score), verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LLMEstimatorWrapper</label><div class=\"sk-toggleable__content\"><pre>LLMEstimatorWrapper(batch_size=1,\n","                    callbacks_after_inference=[&lt;bound method MultiTokenStoppingCriteria.reset of &lt;llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40&gt;&gt;],\n","                    device=&#x27;cuda:0&#x27;, do_sample=True, generation_seed=42,\n","                    is_fitted_=True, max_new_tokens=500,\n","                    model=MistralAWQForCausalLM(\n","  (model): MistralForCausalLM(\n","    (model): LlamaLi...\n","\t32000: AddedToken(&quot;&lt;|im_end|&gt;&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32001: AddedToken(&quot;&lt;|im_start|&gt;&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","},\n","                    tokenizer_decode_args={&#x27;skip_special_tokens&#x27;: True,\n","                                           &#x27;spaces_between_special_tokens&#x27;: False},\n","                    tokenizer_encode_args={&#x27;add_special_tokens&#x27;: False,\n","                                           &#x27;padding&#x27;: &#x27;longest&#x27;},\n","                    top_k=10, top_p=0.8)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LLMEstimatorWrapper</label><div class=\"sk-toggleable__content\"><pre>LLMEstimatorWrapper(batch_size=1,\n","                    callbacks_after_inference=[&lt;bound method MultiTokenStoppingCriteria.reset of &lt;llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40&gt;&gt;],\n","                    device=&#x27;cuda:0&#x27;, do_sample=True, generation_seed=42,\n","                    is_fitted_=True, max_new_tokens=500,\n","                    model=MistralAWQForCausalLM(\n","  (model): MistralForCausalLM(\n","    (model): LlamaLi...\n","\t32000: AddedToken(&quot;&lt;|im_end|&gt;&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","\t32001: AddedToken(&quot;&lt;|im_start|&gt;&quot;, rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n","},\n","                    tokenizer_decode_args={&#x27;skip_special_tokens&#x27;: True,\n","                                           &#x27;spaces_between_special_tokens&#x27;: False},\n","                    tokenizer_encode_args={&#x27;add_special_tokens&#x27;: False,\n","                                           &#x27;padding&#x27;: &#x27;longest&#x27;},\n","                    top_k=10, top_p=0.8)</pre></div></div></div></div></div></div></div></div></div></div>"],"text/plain":["GridSearchCV(cv=2,\n","             estimator=LLMEstimatorWrapper(batch_size=1,\n","                                           callbacks_after_inference=[<bound method MultiTokenStoppingCriteria.reset of <llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>>],\n","                                           device='cuda:0', do_sample=True,\n","                                           generation_seed=42, is_fitted_=True,\n","                                           max_new_tokens=500,\n","                                           model=MistralAWQForCausalLM(\n","  (model): Mistra...\n","                                                                  'padding': 'longest'},\n","                                           top_k=10, top_p=0.8),\n","             param_grid={'do_sample': [True], 'generation_seed': [42],\n","                         'max_new_tokens': [500], 'no_repeat_ngram_size': [0],\n","                         'stopping_criteria': [[<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>]],\n","                         'top_k': [10, 50, 60, 70, 80],\n","                         'top_p': [0.7, 0.75, 0.8, 0.95]},\n","             scoring=make_scorer(get_score), verbose=3)"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["clf.fit(X=tuner_ob.dataset[\"_X\"], y=tuner_ob.dataset['_y'])"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":[" 10%|█         | 15/150 [00:43<05:49,  2.59s/it]"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 150/150 [05:57<00:00,  2.38s/it]\n"]}],"source":["scores_after, outputs_after = tuner_ob.get_score(clf.best_params_)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.72 0.7266666666666667\n"]}],"source":["print(scores_before, scores_after)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["\"{'do_sample': True, 'generation_seed': 42, 'max_new_tokens': 500, 'no_repeat_ngram_size': 0, 'stopping_criteria': [<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], 'top_k': 10, 'top_p': 0.8}\""]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["str(clf.best_params_)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["\n","d = {\n","    'scores_before' : scores_before,\n","    'scores_after' : scores_after,\n","    'outputs_before' : outputs_before,\n","    'outputs_after' : outputs_after,\n","    'best_params' : str(clf.best_params_),\n","}\n","\n","f = \"./gsm-8k-best-params-150s-capybara-7b.json\"\n","json_dump(d, f)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["d = json_load(\"./gsm-8k-best-params-150s-capybara-7b.json\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'do_sample': True, 'generation_seed': 42, 'max_new_tokens': 500, 'no_repeat_ngram_size': 0, 'stopping_criteria': [<llmsearch.scripts.stopping_criteria.MultiTokenStoppingCriteria object at 0x7f8f9e357c40>], 'top_k': 10, 'top_p': 0.8}\n"]}],"source":["print(d['best_params'])"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# harcoding from above file here due to notebook re-run\n","\n","best_params = {\n","    'do_sample' : True,\n","    'generation_seed' : 42,\n","    'max_new_tokens' : 500,\n","    'no_repeat_ngram_size' : 0,\n","    'stopping_criteria' : stopping_criteria,\n","    'top_k' : 10,\n","    'top_p' : 0.8\n","}"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 500/500 [00:00<00:00, 9677.50 examples/s]\n","100%|██████████| 500/500 [20:25<00:00,  2.45s/it]\n"]}],"source":["# eval on test samples\n","\n","gen_params1 = {\n","    \"max_new_tokens\": 500,\n","    \"stopping_criteria\": stopping_criteria,\n","    \"generation_seed\": 42,\n","}\n","\n","oos_scores_before, oos_outputs_before = tuner_ob.get_score(gen_params1,test_dataset)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"data":{"text/plain":["0.564"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["oos_scores_before"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["{'question': 'John climbs up 9 flights of stairs.  Each flight is 10 feet.  If each step is 18 inches, how many steps does he climb up?',\n"," 'answer': 'He has to climb 9*10=<<9*10=90>>90 feet\\nThat means he needs to climb 90*12=<<90*12=1080>>1080 inches\\nThat means he needs to climb 1080/18=<<1080/18=60>>60 stairs\\n#### 60',\n"," 'X': '<|im_start|>system\\nSolve the following math problems, end with The answer is<|im_end|>\\n<|im_start|>user\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\nA: There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\nA: There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\\n\\nQ: John climbs up 9 flights of stairs.  Each flight is 10 feet.  If each step is 18 inches, how many steps does he climb up?<|im_end|>\\n<|im_start|>assistant\\n',\n"," 'actual input': 'John climbs up 9 flights of stairs.  Each flight is 10 feet.  If each step is 18 inches, how many steps does he climb up?'}"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["test_dataset[1]"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Map: 100%|██████████| 500/500 [00:00<00:00, 9790.44 examples/s]\n","100%|██████████| 500/500 [21:14<00:00,  2.55s/it]\n"]}],"source":["\n","oos_scores_after, oos_outputs_after = tuner_ob.get_score(clf.best_params_,test_dataset)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.564 0.584\n"]}],"source":["print(oos_scores_before, oos_scores_after)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["d = {\n","    'scores_before' : scores_before,\n","    'scores_after' : scores_after,\n","    'outputs_before' : outputs_before,\n","    'outputs_after' : outputs_after,\n","\n","    'oos_scores_before' : oos_scores_before,\n","    'oos_scores_after' : oos_scores_after,\n","    'oos_outputs_before' : oos_outputs_before,\n","    'oos_outputs_after' : oos_outputs_after,\n","    'best_params' : str(clf.best_params_),\n","}\n","\n","f = \"./gsm-8k-best-params-150s-capybara-7b.json\"\n","json_dump(d, f)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"llmsearch-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":2}
